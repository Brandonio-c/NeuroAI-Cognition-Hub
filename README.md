# NeuroAI-Cognition-Hub
## Neuro-Symbolic AI and Cognition Links

Welcome to the Neuro-Symbolic AI and Cognition Links repository. This repository is a curated collection of resources, links, and references related to the exciting field of neuro-symbolic artificial intelligence, with a specific focus on cognition within AI. Whether you're a researcher, student, or AI enthusiast, this repository aims to provide valuable information and references to help you dive deeper into this evolving field.  Dive into the world of cognitive models, architectures, and AI systems that aim to simulate human-like thinking processes. Stay up-to-date with the latest developments and research in this cutting-edge domain, and contribute to our growing repository to help advance the field even further. Join us in the exploration of the fascinating intersection of neuroscience, symbolic reasoning, and AI cognition.

## Table of Contents

1.  [About Neuro-Symbolic AI and the Common Model of Cognition](#about-neuro-symbolic-ai)
2.  [Cognition in AI - 2024 synopsis](#cognition-in-ai)
3.  [Featured](#featured)
4.  [Survey papers](#Survey-Papers)
5.  [Symbolic Language](#Symbolic-Language)
6.  [Symbolic Reasoning AI major projects](#Symbolic-Reasoning-AI-major-projects)
7.  [Neuro-symbolic AI major projects](#Neuro-Symbolic-AI-major-projects)
8.  [Knowledge representation major projects](#Knowledge-representation-major-projects)
9.  [Cognitive Architectures and Generative Models](#Cognitive-Architectures-and-Generative-Models)
10.  [Common Model of Cognition](#Common-Model-of-Cognition)
11.  [Memory AI major projects](#Memory-AI-major-projects)
12.  [Meta-level control major projects](#Meta-level-control-major-projects)
13. [Benchmarks](#benchmarks)
14. [Generative AI Impactful Projects](#Generative-AI-Impactful-Projects)
15. [Useful AI tools (2024) - There's literally an AI for everything](#useful-ai-tools-2024---theres-literally-an-ai-for-everything)
16. [Links to other useful GitHub pages](#links-to-other-useful-github-pages)
17. [Usage](#usage)
18. [Contributing](#contributing)
19. [License](#license)

Up to week 10 day 00 (just started this week)

## About Neuro-Symbolic AI

Neuro-symbolic AI is an interdisciplinary approach that combines symbolic reasoning with neural networks to create more advanced and intelligent AI systems. This repository will provide links to research papers, articles, and tools that explore this integration.

## Cognition in AI

Cognition within AI is an essential aspect of building machines that can think and understand like humans. We've gathered resources related to cognitive models, cognitive architectures, and AI systems that simulate human-like thinking processes.

### The Grounding Problem 

### The Common Model of Cognition

## Featured 

- [![Website](https://img.shields.io/badge/Website-HuggingFace-red)](https://huggingface.co/) - AI model and dataset repository

- [![Website](https://img.shields.io/badge/Website-Deep_Learning_Is_Hitting_A_Wall-red)](https://nautil.us/deep-learning-is-hitting-a-wall-238440/) - "Deep Learning Is Hitting a Wall" by Gary Marcus.

- [![GitHub](https://img.shields.io/badge/Website-OpenCog-red)](https://github.com/opencog) - Visit the GitHub repository for OpenCog.

- [![Website](https://img.shields.io/badge/Website-IHMC-red)](https://www.ihmc.us/publications-on-explainable-ai/) - Publications on Explainable AI


## Survey Papers

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2023](https://arxiv.org/abs/2111.08164) | NeuralSym | A Survey on Neural-symbolic Learning Systems | [![arXiv ](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2111.08164) | N/A | <details><summary>Summary</summary>"A Survey on Neural-symbolic Learning Systems" examines the combination of neural networks and symbolic AI. It covers the AI evolution, integration challenges, and methods like learning for reasoning, reasoning for learning, and a joint approach. The survey highlights efficiency, generalization, interpretability improvements, diverse applications, and future research directions in AI.<br>- Discusses neural-symbolic system integration<br>- Explores AI evolution, challenges, and methodologies</details> |
| [2023](https://arxiv.org/abs/2305.08876) | NeuroTax | Neurosymbolic AI and its Taxonomy: a survey | [![arXiv ](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2305.08876) | N/A | <details><summary>Summary</summary>"Neurosymbolic AI and its Taxonomy: A Survey" explores the integration of neural networks with symbolic AI towards AGI. It covers AI evolution, knowledge representation, learning and reasoning processes, and emphasizes the importance of explainability and trustworthiness in AI. The survey analyzes various neurosymbolic models, their applications, and suggests future research directions, offering an overview of neurosymbolic AI's advancements, methodologies, and prospects.<br>- Discusses AI evolution and complexity<br>- Analyzes neurosymbolic models and applications</details> |
| [2023](https://arxiv.org/abs/2012.05876) | NeuroWave | Neurosymbolic AI: The 3rd Wave | [![arXiv ](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2012.05876) | N/A | <details><summary>Summary</summary>"Neurosymbolic AI: The 3rd Wave" provides a comprehensive analysis of the merging of neural networks and symbolic AI. Highlighting the field's evolution, it discusses current debates and technical aspects of neurosymbolic computing. The paper stresses the need for integrating learning and reasoning, efficiency, scalability, and trust in AI. It compares different models and discusses the AAAI 2020 conference's role in advancing neurosymbolic AI. The paper calls for leveraging both symbolic and neural approaches for more advanced AI systems.<br>- Emphasizes integration of neural and symbolic AI<br>- Discusses AI challenges and model comparisons</details> |
| [2023](https://arxiv.org/abs/2003.00330) | GNN-NSC Survey | Graph Neural Networks Meet Neural-Symbolic Computing | [![arXiv ](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2003.00330) | N/A | <details><summary>Summary</summary>This survey explores the integration of Graph Neural Networks (GNNs) with Neural-Symbolic Computing (NSC). It delves into various GNN models, their application in relational learning, reasoning, and combinatorial optimization. The paper emphasizes GNNs' role in efficiency, scalability, and real-world applications, addressing integration challenges and future research directions. It highlights the importance of explainability and trust in AI systems, offering a comprehensive view of GNNs' potential in NSC.<br>- Discusses GNN models and applications<br>- Explores integration challenges and future directions</details> |
| [2022](https://ieeexplore-ieee-org.proxy-um.researchport.umd.edu/document/9416312) | KnowledgeGraph | A Survey on Knowledge Graphs: Representation, Acquisition, and Applications | [![IEEE](https://img.shields.io/badge/IEEE-2022-blue)](https://ieeexplore-ieee-org.proxy-um.researchport.umd.edu/document/9416312) | N/A | <details><summary>Summary</summary>The survey on knowledge graphs offers a comprehensive review of their representation, acquisition, and applications. It delves into knowledge graph embedding, focusing on aspects like representation space, scoring functions, and encoding models, and includes auxiliary information. The study also explores knowledge acquisition, especially graph completion, through methods like embedding, path inference, and logical reasoning. It highlights applications in natural language understanding and recommendation systems. Emerging topics, such as transformer-based encoding and graph neural networks, are addressed. The survey also discusses entity discovery and neural relation extraction, incorporating modern techniques like attention mechanisms. Future research directions and resources for knowledge graph research are provided.</details> |
| [2021](https://arxiv.org/abs/2109.06133) | NSAI | Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization | [![arXiv ](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2109.06133) | [![GitHub](https://img.shields.io/github/stars/vacancy/NSCL-PyTorch-Release.svg?style=social)](https://github.com/vacancy/NSCL-PyTorch-Release), [![GitHub](https://img.shields.io/github/stars/chuangg/CLEVRER.svg?style=social)](https://github.com/chuangg/CLEVRER), [![GitHub](https://img.shields.io/github/stars/facebookresearch/d2go.svg?style=social)](https://github.com/facebookresearch/d2go), [![GitHub](https://img.shields.io/github/stars/OpenNMT/OpenNMT-py.svg?style=social)](https://github.com/OpenNMT/OpenNMT-py), [![GitHub](https://img.shields.io/github/stars/YunzhuLi/PropNet.svg?style=social)](https://github.com/YunzhuLi/PropNet), [![GitHub](https://img.shields.io/github/stars/google/neural-logic-machines.svg?style=social)](https://github.com/google/neural-logic-machines) | <details><summary>Summary</summary>Neuro-symbolic AI (NSAI) represents a novel integration of traditional rules-based AI approaches with modern deep learning techniques, offering advancements in image and video reasoning while reducing the need for extensive training data. This paper provides an in-depth analysis of three distinct NSAI models: the Neuro-Symbolic Concept Learner (NSCL), Neuro-Symbolic Dynamic Reasoning (NS-DR), and Neural Logic Machines (NLM). While NSCL and NS-DR are composed of several submodels including image/video parsers and symbolic executors, NLM functions as an end-to-end model. The analysis reveals that NSAI models generally exhibit less potential for parallelism compared to traditional neural models, primarily due to their complex control flow and operations such as scalar multiplication. Data movement is highlighted as a potential bottleneck, similar to other machine learning workloads. The paper categorizes the operations within NSAI models into eight types for performance analysis, suggesting that while the neural components often dominate, there are opportunities for acceleration, especially in handling low-operational-intensity operations.</details> |


## Neuro-symbolic AI major projects

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2024](https://openreview.net/forum?id=NzjyY2Z9zJd) | neuro symbolic text game | A Hybrid Neuro-Symbolic approach for Text-Based Games using Inductive Logic Programming | [![Paper](https://img.shields.io/badge/Paper-2024-blue)](https://openreview.net/forum?id=NzjyY2Z9zJd) | N/A | <details><summary>Summary</summary>This paper presents a hybrid neuro-symbolic architecture for Text-Based Games (TBGs), combining symbolic reasoning with neural reinforcement learning. It uses inductive logic programming to learn symbolic rules as default theories with exceptions, enabling non-monotonic reasoning in partially observable environments. The approach employs WordNet for rule generalization, enhancing adaptability to unseen objects and scenarios. The architecture features a context encoder, action encoder, neural and symbolic action selectors, and a symbolic rule learner, with priority given to symbolic reasoning. The model outperforms traditional methods in TBGs, showing potential for future improvements in action selection and agent adaptability </details> |
| [2024](https://openreview.net/forum?id=ORAhay0H4x) |Plan-SOFAI | Plan-SOFAI: A Neuro-Symbolic Planning Architecture | [![Paper](https://img.shields.io/badge/Paper-2024-blue)](https://openreview.net/forum?id=ORAhay0H4x) | NA | <details><summary>Summary</summary> Plan-SOFAI introduces a neuro-symbolic architecture for AI planning inspired by Kahneman's cognitive theory. It integrates fast (System-1) and slow (System-2) thinking models, utilizing System-1 for quick solutions based on past experiences and System-2 for logical, reasoned approaches. A metacognitive module oversees solver selection, balancing speed and accuracy. Focused on classical planning problems, Plan-SOFAI demonstrates versatility and efficiency in various testing scenarios, outperforming traditional methods in balancing solving speed and solution optimality. The architecture's adaptability allows integration of new techniques, promising broader applications beyond classical planning. Future efforts aim to enhance Plan-SOFAI's capabilities and explore new domains of application.</details> |
| [2023](https://arxiv.org/abs/2312.03905) | PseudoSL | Research on Pseudo Supervised Learning | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2312.03905) | [![GitHub](https://img.shields.io/github/stars/UCLA-StarAI/PseudoSL.svg?style=social)](https://github.com/UCLA-StarAI/PseudoSL) | <details><summary>Summary</summary>The paper introduces a novel Pseudo-Semantic Loss for Autoregressive Models to incorporate logical constraints into deep learning training processes. Addressing the computational complexity of maximizing symbolic constraint likelihoods in expressive distributions like transformers, the approach employs a pseudolikelihood-based approximation around a model sample. This innovation ensures the efficient computation of neuro-symbolic losses. Empirically validated across diverse tasks like Sudoku solving, Warcraft path prediction, and language model detoxification, the method significantly improves the production of logically consistent outputs and reduces language model toxicity. This work extends neuro-symbolic learning, combining symbolic knowledge representation with neural network capabilities, and enhancing model reliability and explainability. </details> |
| [2023](https://arxiv.org/abs/2302.14207) | SemStreng | Study on Semantic Strengthening | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2302.14207) | [![GitHub](https://img.shields.io/github/stars/UCLA-StarAI/Semantic-Strengthening.svg?style=social)](https://github.com/UCLA-StarAI/Semantic-Strengthening) | <details><summary>Summary</summary>The paper introduces "Semantic Strengthening of Neuro-Symbolic Learning," addressing the computational challenges in neuro-symbolic methods. It iteratively strengthens an approximation by focusing on the most relevant constraints, measured through conditional mutual information. This process ensures better alignment of gradients between constraint distributions, enhancing the model's accuracy in structured-output tasks. The approach efficiently computes mutual information using tractable circuits and maintains sound probabilistic semantics. Evaluated on complex tasks like Warcraft path prediction, Sudoku solving, and MNIST matching, the method significantly improves prediction accuracy. This work combines neural networks' feature extraction prowess with symbolic reasoning, offering a scalable solution for advanced neuro-symbolic learning. </details> |
| [2023](https://arxiv.org/abs/2309.16467) | CPG | Code property graph framework for software analysis | [![arXiv ](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2309.16467) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/IBM/cpg) | <details><summary>Summary</summary>The "Compositional Program Generator" (CPG) is a novel neuro-symbolic architecture designed for efficient language processing, particularly in few-shot learning scenarios. Unlike conventional neural networks, which struggle with systematic generalization and require extensive data, CPG excels in learning new concepts with minimal examples. Its core strengths lie in three attributes: modularity, where it uses specialized modules for different semantic functions; composition, allowing the combination of modules for varied input types; and abstraction, employing grammar rules for consistent input processing. CPG's innovative approach is showcased through its remarkable performance on standard benchmarks like SCAN and COGS, achieving state-of-the-art results with drastically fewer data samples. This efficiency is facilitated by its curricular training method, which incrementally adjusts to varying sentence lengths and complexities. CPG's ability to retrain efficiently for new concepts or grammar adaptations, without forgetting previous learnings, indicates its potential for broader applications in systematic language generalization tasks.</details> |
| [2023](https://arxiv.org/abs/2305.19374) | NeuroConcept | Compositional diversity in visual concept learning | [![arXiv 2023](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2305.19374) | N/A yet | <details><summary>Summary</summary> This study investigates human abilities in learning and generating novel visual concepts through compositionality, contrasting with limitations in computer vision models. Using "alien figures," it explores how humans classify and create these figures. Experiments reveal humans’ strong inductive biases and nuanced behaviors, particularly in generating novel patterns. A Bayesian program induction model captures a range of compositional behaviors, but struggles with subtle nuances observed in human responses. To address this, a generative neuro-symbolic model is introduced, blending neural networks with symbolic representations. The research underscores the complexity of human visual concept learning and the challenges in computationally modeling it.  </details> |
| [2023](https://ibm.github.io/neuro-symbolic-ai/toolkit/ulkb/) | ULKB  | Universal Logic Knowledge Base | N/A | [![GitHub](https://img.shields.io/github/stars/ibm/ulkb.svg?style=social)](https://github.com/ibm/ulkb) | <details><summary>Summary</summary> The Universal Logic Knowledge Base (ULKB) by IBM is a Higher Order Logic (HOL)-based framework designed for reasoning over knowledge graphs. ULKB consists of two primary components: ULKB Logic, a HOL language and interactive theorem-prover environment, and ULKB Graph, a core knowledge graph enhanced by external knowledge bases. The repository, hosted on GitHub, includes ULKB Logic's Python library source code, with examples and tutorials located in the 'examples' directory. The repository also features ontology files and graph generation code under 'graph', along with testing code. The project supports reasoning in complex knowledge domains, emphasizing logic, knowledge graphs, and theorem proving. Installation and testing instructions are provided, highlighting its ease of use for developers and researchers in knowledge representation and reasoning. </details> |
| [2023](https://openreview.net/forum?id=VD0ksRTljb) | IBM-LNN | Learning Neuro-Symbolic World Models with Logical Neural Networks | [![Paper](https://img.shields.io/badge/Paper-2023-blue)](https://openreview.net/forum?id=VD0ksRTljb) | [![GitHub](https://img.shields.io/github/stars/IBM/LNN.svg?style=social)](https://github.com/IBM/LNN) | <details><summary>Summary</summary> he paper introduces a neuro-symbolic framework using Logical Neural Networks (LNN) for model-based reinforcement learning, addressing real-world problems needing explainable models and limited training data. It employs LNNs for scalable rule learning, integrated with object-centric perception modules and AI planners. The framework excels in PDDLGym environments and significantly outperforms existing agents in the TextWorld-Commonsense domain. It adeptly handles noisy data, leverages STRIPS operators for modeling actions, and enhances exploration in relational RL. This work significantly contributes to neuro-symbolic learning, showcasing its practical application in constructing robust, interpretable AI planning systems and advancing the field of artificial intelligence. </details> |
| [2023](https://aclanthology.org/2023.acl-short.57/) | IBM-Proprioception | Neuro-Symbolic World Models with Conversational Proprioception | [![Paper](https://img.shields.io/badge/Paper-2023-blue)](https://aclanthology.org/2023.acl-short.57/) | N/A | <details><summary>Summary</summary> This paper presents a novel method for learning neuro-symbolic world models in text-based games using Logical Neural Networks (LNN). Focusing on the TextWorld-Commonsense set of games, it introduces the concept of conversational proprioception, enhancing model-based reinforcement learning by incorporating the memory of previous actions and constraints based on this memory. The approach significantly improves game-solving performance, as evidenced by substantial reductions in average steps and increases in average scores. Utilizing semantic parsing for logical state approximation and planning with learned logical models, the method provides better explainability and effectiveness in decision-making compared to existing neuro-symbolic agents. </details> |
| [2023](https://arxiv.org/abs/2110.10973) | IBM-LOA | Learning Neuro-Symbolic World Models with Conversational Proprioception | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2110.10973) | [![GitHub](https://img.shields.io/github/stars/ibm/loa.svg?style=social)](https://github.com/ibm/loa) | <details><summary>Summary</summary> LOA (Logical Optimal Actions) is a novel reinforcement learning architecture that combines neural networks and symbolic logic for text-based interaction games. It leverages Logical Neural Networks (LNN) for logical reasoning, rule training, and improved interpretability of AI decisions. The framework focuses on language understanding, requiring skills such as long-term memory and common sense reasoning, within complex text-based game environments. LOA is demonstrated through a web-based platform, allowing users to play text-based games and visualize logical rule learning. An open-source implementation enhances its accessibility for experimentation. LOA represents a significant step in applying neuro-symbolic approaches to real-world language-based interactions. </details> |
| [2022](https://arxiv.org/abs/2212.12050) | Semantic NS computing | A Semantic Framework for Neural-Symbolic Computing | [![arXiv 2022](https://img.shields.io/badge/arXiv-2022-brightgreen)](https://arxiv.org/abs/2212.12050) | N/A | <details><summary>Summary</summary>Simon Odense and Artur d’Avila Garcez's paper, "A Semantic Framework for Neural-Symbolic Computing," presents an innovative framework integrating neural networks and symbolic artificial intelligence. This integration addresses the limitations of both approaches, proposing a standard for encoding symbolic knowledge into neural networks. It covers key aspects like semantic encoding, probabilistic models, and semantic regularization, contributing significantly to explainable AI. The framework enables a unified understanding and comparison of diverse neural-symbolic methods. Although it faces challenges like expressive limitations, this pioneering work lays the groundwork for future advancements in neural-symbolic computing, a crucial step towards more advanced, interpretable AI systems. </details> |
| [2021](https://arxiv.org/abs/2110.10963) | Neuro-Symbolic RL | Neuro-Symbolic Reinforcement Learning with First-Order Logic | [![Paper](https://img.shields.io/badge/Paper-arXiv'21-brightgreen)](https://arxiv.org/abs/2110.10963) | [![Toolkit](https://img.shields.io/badge/Toolkit-IBM-red)](https://ibm.github.io/neuro-symbolic-ai/toolkit/) | <details><summary>Summary</summary> The paper presents a novel neuro-symbolic reinforcement learning approach for text-based games, utilizing Logical Neural Networks (LNN) to convert observations into logical facts and train interpretable policies. The method, which outperforms state-of-the-art approaches in convergence speed and interpretability, first transforms text observations into first-order logical facts with the aid of ConceptNet. LNNs are then employed to learn symbolic rules, merging neural network learning with logical reasoning. Experiments on TextWorld games across varying difficulty levels demonstrate the method’s effectiveness. The approach offers increased transparency by enabling the extraction of logical rules, addressing ethical considerations of model interpretability and ensuring computational efficiency. </details> |
| [2021](https://aclanthology.org/2021.emnlp-main.245/) | SLATE | Neuro-Symbolic Approaches for Text-Based Policy Learning | [![Paper](https://img.shields.io/badge/Paper-EMNLP'21-blue)](https://aclanthology.org/2021.emnlp-main.245/) | N/A | <details><summary>Summary</summary> SLATE introduces a novel neuro-symbolic approach for interpretable policy learning in text-based games, using symbolic rule learning from textual observations. It significantly improves generalization to unseen games and outperforms previous methods with fewer training games. SLATE learns interpretable and logically consistent action rules through gradient-based training, employing both MLP and LNN models. It offers clear insights into the learned policy, contributing to more reliable and ethically sound AI systems. Future work aims to extend SLATE to handle a broader range of predicates and domain-agnostic graphical states, further enhancing its applicability and effectiveness in natural language reinforcement learning. </details> |
| [2021](https://ieeexplore.ieee.org/document/9415044) | PLNN | Training Logical Neural Networks by Primal–Dual Methods for Neuro-Symbolic Reasoning | [![IEEE](https://img.shields.io/badge/Conference-IEEE'21-blue)](https://ieeexplore.ieee.org/document/9415044) | [![Star](https://img.shields.io/github/stars/songtaogithub/LNN.svg?style=social)](https://github.com/songtaogithub/LNN) | <details><summary>Summary</summary> "Training Logical Neural Networks by Primal–Dual Methods for Neuro-Symbolic Reasoning" explores the training of Logical Neural Networks (LNNs) under challenging constraints. The paper introduces a unified framework utilizing primal-dual optimization for this purpose, focusing on achieving convergence to KKT points in non-linear, nonconvex optimization scenarios. The proposed Inexact Alternating Direction Method of Multipliers (iADMM) effectively addresses the complexities in training LNNs by handling nonconvex inequality constraints. This advancement demonstrates superior results in training LNN models on real-world data sets, validating the approach's efficiency. The work sets a precedent for future research in optimizing LNNs, a vital tool for neuro-symbolic AI. </details> |
| [2020](https://arxiv.org/abs/2012.13635) | LTN | Logic Tensor Networks | [![arXiv 2020](https://img.shields.io/badge/arXiv-2020-brightgreen)](https://arxiv.org/abs/2012.13635) | [![Star](https://img.shields.io/github/stars/logictensornetworks/logictensornetworks.svg?style=social)](https://github.com/logictensornetworks/logictensornetworks) | <details><summary>Summary</summary> Logic Tensor Networks (LTN) present a neurosymbolic AI framework, integrating logic and neural networks through a differentiable logical language, Real Logic. It grounds symbols from first-order logic onto data using neural networks, allowing rich knowledge representation and reasoning. LTN supports diverse AI tasks like classification, clustering, and regression. Learning involves parameter optimization to maximize formula satisfiability, while querying enables evaluation of truth values and inferences on new data. The framework includes methods for logical reasoning and addresses gradient issues through stable product real logic. Implemented in TensorFlow 2, LTN combines efficient computation with the expressiveness of first-order logic. </details> |

## Symbolic Language

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2002-22](https://propbank.github.io/) | PropBank | PropBank (proposition bank) approach to semantic role labeling over the last two decades | [![Paper](https://img.shields.io/badge/Paper-ACL'22-blue)](https://aclanthology.org/2022.starsem-1.24/) | [![GitHub](https://img.shields.io/github/stars/propbank/propbank.svg?style=social)](https://github.com/propbank/) | <details><summary>Summary</summary>PropBank, evolving over twenty years, has significantly expanded its scope, encompassing non-verbal predicates such as adjectives, prepositions, and multi-word expressions, as well as a broader range of domains, genres, and languages. This expansion enhances the testing and generalization capabilities of semantic role labeling (SRL) systems. PropBank's methodology, focusing on semantic role labeling, has transitioned from relying on syntactic parses to richer semantic representations. A key component of PropBank is its Frames, housing rolesets with predicate argument structures, now essential to various meaning representations like AMR and UMR. Recent developments include the inclusion of non-verbal predicates and an extensive overhaul of the lexicon to support domain-specific annotation projects such as Spatial AMR and the THYME project. These adaptations have increased PropBank's utility and relevance in diverse NLP applications. PropBank's enhanced web presence, user-friendly tools, and accessibility improvements, such as utility scripts and a searchable frame files website, have made it a more powerful resource for researchers and practitioners in the field.</details> |
| [2017-22](https://universalpropositions.github.io/) | Universal PropBank | Annotate text in different languages with a layer of "universal" semantic role labeling annotation | [![Website](https://img.shields.io/badge/Website-See_Publications-blue)](https://universalpropositions.github.io/) | [![GitHub](https://img.shields.io/github/stars/UniversalPropositions/UniversalPropBank.svg?style=social)](https://github.com/UniversalPropositions) | <details><summary>Summary</summary>The Universal Proposition Banks (UP) project aims to annotate texts in various languages with "universal" semantic role labeling, using English Proposition Bank's frame and role labels. UP2.0, an enhancement over v1.0, offers higher quality PropBanks using advanced monolingual SRL and improved annotation auto-generation. It expands language coverage from 7 to 23 and introduces span annotation for syntactic analysis decoupling, along with Gold data for some languages. UP2.0 is built on the Universal Dependency Treebanks release 2.9, utilizing English PropBank version 3.0 labels. The project focuses on annotating verbs with English frames, excluding auxiliary verbs, and aims to label about 90% of all verbs in each language. The annotations, mostly model-predicted, vary in quality due to domain differences. UP facilitates research in multilingual and cross-lingual SRL, with applications in advanced NLP and IBM products. Future work includes adding new languages and improving annotation quality. UP2.0 provides a valuable resource for expanded shallow semantic parsing and semantic role labeling research and applications.</details> |
| [2012-18](https://verbs.colorado.edu/verbnet/) | VerbNet | The largest online network of English verbs that links their syntactic and semantic patterns | [![Website](https://img.shields.io/badge/Website-VerbNet-red)](https://verbs.colorado.edu/verbnet/) | [![GitHub](https://img.shields.io/github/stars/cu-clear/verbnet.svg?style=social)](https://github.com/cu-clear/verbnet) | <details><summary>Summary</summary>VerbNet (VN) is the largest online English verb lexicon, providing a hierarchical, domain-independent verb classification system. It extends and refines Levin's classes for syntactic and semantic coherence. Each class includes thematic roles, selectional restrictions, and frames combining syntactic descriptions with semantic predicates and temporal functions. VN integrates Levin's work with extensions by Korhonen and Briscoe, expanding its coverage, including verbs taking various complements. The integration enriches VN, increasing its classes, thematic roles, semantic predicates, and syntactic restrictions. This comprehensive Levin-style classification is essential for creating training corpora for syntactic parsers and semantic role labelers. VN's thematic role assignments and class memberships facilitate large-scale experimentation in syntax-based class utility for improving NLP tools.</details> |
| [2021](https://aclanthology.org/2021.iwcs-1.21/) | IWCS21 | Semantic linking in computational linguistics | [![Paper](https://img.shields.io/badge/Paper-2021-blue)](https://aclanthology.org/2021.iwcs-1.21/) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/cu-clear/semlink) | <details><summary>Summary</summary>SemLink serves as a vital bridge connecting lexical semantic resources like PropBank, VerbNet, FrameNet, and WordNet. It enables the use of each resource's unique features, thereby enhancing semantic analysis capabilities. Recent updates have focused on automatic and manual enhancements to maintain consistency across evolving resources, alongside the introduction of sense embeddings and subject/object information. SemLink's size has nearly doubled through these updates, significantly improving its coverage. Essential for research in lexical semantics, word sense disambiguation, and semantic role labeling, SemLink continues to evolve, with future efforts aimed at filling gaps through manual annotation and evaluating the utility of linked resources</details> |
| [2019](https://aclanthology.org/N19-1334.pdf) | Wilcox19 | Structural analysis in natural language processing | [![Paper](https://img.shields.io/badge/Paper-N19--1334-blue)](https://aclanthology.org/N19-1334/) | N/A | <details><summary>Summary</summary>This study investigates whether training language models with hierarchical structure supervision improves their ability to learn non-local grammatical dependencies, previously only examined for subject-verb agreement. By comparing LSTM models with two structurally supervised models – Recurrent Neural Network Grammars (RNNGs) and a version of Parsing-as-Language-Modeling – the research focuses on two grammatical dependencies: Negative Polarity licensing and Filler–Gap Dependencies. Findings reveal that structurally supervised models significantly outperform traditional LSTMs, particularly in RNNGs, which show superior understanding of complex grammatical rules. These results highlight the benefits of structural supervision in language model training, especially for complex grammatical learning </details> |
| [2017](https://users.cs.utah.edu/~lifeifei/papers/deeplog.pdf) | DeepLog | Anomaly detection in system logs through deep learning | [![acm ](https://img.shields.io/badge/Paper-2017-blue)](https://dl.acm.org/doi/10.1145/3133956.3134015) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/Thijsvanede/DeepLog) | <details><summary>Summary</summary>DeepLog leverages a deep neural network, specifically Long Short-Term Memory (LSTM), to analyze system logs for anomaly detection. It treats logs as natural language sequences, learning normal patterns for identifying deviations. Uniquely, DeepLog continually updates its model to adapt to new log patterns over time, enhancing its relevance and accuracy. The system is capable of diagnosing anomalies by constructing workflows from logs, offering insights into potential root causes. DeepLog proves effective in various settings, including HDFS and OpenStack logs, outperforming traditional data mining methods in detecting both execution path and parameter value anomalies, showcasing its versatility and dynamic adaptability.</details> |
| [2015](https://aclanthology.org/Q15-1034/) | Semantic Proto-roles | Semantic proto role linking model | [![Paper](https://img.shields.io/badge/Paper-Q15--1034-blue)](https://aclanthology.org/Q15-1034/) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/aaronstevenwhite/SemanticProtoRoleLinkingModel?tab=readme-ov-file) | <details><summary>Summary</summary>The study presents a large-scale corpus-based validation of Dowty's proto-role theory, proposing a shift from traditional categorical roles to a property-based annotation in understanding semantic relationships. It harnesses crowdsourcing to gather data on proto-agent and proto-patient properties across sentences in the PropBank corpus. Analyzing 11 proto-role properties, the study reveals significant role fragmentation with a wide array of unique property configurations. This approach highlights the nuanced nature of semantic roles, challenging existing frameworks like VerbNet and FrameNet. The findings offer significant insights for applications in semantic parsing and role labeling, with future expansion to other languages and broader linguistic analysis anticipated. </details> |
| [2003](https://ids-pub.bsz-bw.de/frontdoor/deliver/index/docId/5416/file/Johnson_Petruck_Baker_Ellsworth_Ruppenhofer_Fillmore_FrameNet_Theory_and_Practice_2003.pdf) | FrameNet | Linguistic theory and practice analysis | [![Paper](https://img.shields.io/badge/Paper-2003-blue)](https://ids-pub.bsz-bw.de/frontdoor/deliver/index/docId/5416/file/Johnson_Petruck_Baker_Ellsworth_Ruppenhofer_Fillmore_FrameNet_Theory_and_Practice_2003.pdf) | [![Website](https://img.shields.io/badge/Website-FRAMENET-red)](https://framenet.icsi.berkeley.edu/) | <details><summary>Summary</summary>FrameNet is a linguistic project that catalogs the semantic frames of English words, focusing on the roles and relationships between words in sentences. It's based on Frame Semantics, a theory positing that the meaning of a word is best understood in the context of a larger conceptual structure, or "frame". FrameNet provides structured representations of word meanings, identifying the elements and participants involved in different scenarios. This resource is valuable for natural language processing applications like semantic role labeling and text understanding, offering insights into how language constructs meaning through interrelated words and their contextual roles. </details> |
| [1993](https://aclanthology.org/J93-2004/) | Penn Treebank | Linguistic data consortium analysis | [![Paper](https://img.shields.io/badge/Paper-J93--2004-blue)](https://aclanthology.org/J93-2004/) | N/A | <details><summary>Summary</summary>The Penn Treebank project undertakes the ambitious task of building a large annotated corpus of American English, aiming to significantly progress in understanding both written text and spoken language. It involves annotating over 4.5 million words with part-of-speech and skeletal syntactic structure. The POS tagging utilizes a simplified tagset and combines automatic assignment with human correction, ensuring speed, consistency, and accuracy. Bracketing, following a similar process, employs the automatic parser Fidditch for initial analysis. The project's output, crucial for linguistic research and natural language processing, plans future enhancements for more detailed annotations and addressing complexities in linguistic structures. </details> |
| [1990](https://verbs.colorado.edu/~mpalmer/Ling7800/Parsons.pdf) | Parsons1990 | Events in the Semantics of English: A Study in Subatomic Semantics | [![Paper](https://img.shields.io/badge/Paper-Colorado--1990-blue)](https://verbs.colorado.edu/~mpalmer/Ling7800/Parsons.pdf) | N/A | <details><summary>Summary</summary>Terence Parsons' 1990 paper on "Events in the Semantics of English" delves into the Neo-Davidsonian approach to event semantics. It highlights the complexities of semantic representations, addressing how verbs and their associated roles in sentences form a logical structure. The paper solves issues like variable polyadicity, handling multiple roles, and missing roles (e.g., in dream scenarios). It distinguishes between core and non-core roles and utilizes explicit quantification of underlying events, advancing Davidson's 1967 theory by treating all roles as independent conjuncts. The work impacts NLP resources and challenges our understanding of language's logical structure.</details> |
| [1967](https://jamespusto.com/wp-content/uploads/2018/08/Davidson-1967-1.pdf) | Davidson1967 | The Logical Form of Action Sentences | [![arXiv](https://img.shields.io/badge/Paper-Colorado--1967-blue)](https://verbs.colorado.edu/~mpalmer/Ling7800/Davidson.pdf) | N/A | <details><summary>Summary</summary> In "The Logical Form of Action Sentences," Davidson delves into the intricate nature of sentences that describe actions, challenging traditional approaches to their analysis. The essay begins by examining the conventional treatment of action verbs in standard predicate logic, where Davidson finds significant shortcomings. He argues that such an approach fails to capture the complexity of action sentences, particularly in attributing a singular term to actions. Davidson's exploration leads him to question how we understand agency within these sentences. He differentiates between the agent – the doer of the action – and the action itself, proposing that actions can be viewed as events with various descriptions. This perspective allows for a more nuanced analysis of action sentences, considering the multifaceted ways in which actions are expressed and understood. Throughout the essay, Davidson critiques other philosophers' approaches to the logical form of action sentences. He specifically addresses the works of Kenny and Chisholm, pointing out the limitations in their analyses and suggesting that their methods fail to accommodate the complexity of action verbs and their modifiers. In response to these critiques, Davidson proposes a new approach. He suggests considering the inclusion of events as entities in the analysis of action sentences, thereby providing a richer and more accurate representation of their logical form. This perspective enables a better understanding of how intentional actions are expressed in language and their semantic implications. The essay culminates in a discussion on the broader grammatical and semantic consequences of this new approach to analyzing action sentences. Davidson's innovative perspective sheds light on the intricate nature of language and the way we understand actions and intentions within it, offering valuable insights into the philosophy of language. </details> |




## Symbolic Reasoning AI major projects

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2023](https://arxiv.org/abs/2308.04445) | Cyc by Cycorp | Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc | [![arXiv 2023](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2308.04445) | [![Star](https://img.shields.io/github/stars/cycorp/cyc.svg?style=social)](https://github.com/cycorp) | <details><summary>Summary</summary>**10 Point Summary:**<br>1. Addresses limitations of LLMs in trustworthiness and reasoning.<br>2. Proposes integration with symbolic AI, using Cyc as an example.<br>3. Combines strengths of LLMs and symbolic AI.<br>4. Discusses 16 elements necessary for trustworthy AI.<br>5. Emphasizes need for explicit knowledge representation.<br>6. Highlights importance of reasoning, world models, higher-order logic.<br>7. Cyc's common-sense knowledge can enhance LLMs.<br>8. Suggests improved explanation, deduction, induction capabilities.<br>9. Aims to overcome LLMs' shortcomings in complex language.<br>10. Envisions more reliable, interpretable AI systems.<br><br>**Detailed Summary:**<br>The 2023 paper "Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc" by Doug Lenat and Gary Marcus discusses the limitations of current Large Language Models (LLMs) in trustworthiness and reasoning. It proposes integrating LLMs with symbolic AI systems like Cyc to address these limitations. The paper outlines 16 key elements necessary for a trustworthy AI, emphasizing the need for explicit knowledge, reasoning, world models, and higher-order logic capabilities. It suggests that integrating LLMs with systems like Cyc, which can handle complex reasoning and possess extensive common-sense knowledge, could lead to more reliable and interpretable AI systems. This approach aims to overcome the shortcomings of LLMs, particularly in areas like explanation, deduction, induction, and handling of complex language structures.</details> |
| [2023](https://arxiv.org/abs/2306.03553) | ARC | Abstraction and Reasoning Challenge | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2306.03553) | [![GitHub](https://img.shields.io/github/stars/fchollet/ARC.svg?style=social)](https://github.com/fchollet/ARC), [![GitHub](https://img.shields.io/github/stars/tanchongmin/ARC-Challenge.svg?style=social)](https://github.com/tanchongmin/ARC-Challenge) | <details><summary>Summary</summary>The paper discusses using GPT-4 for solving the ARC Challenge, emphasizing learning from limited samples. It contrasts this with traditional deep learning's reliance on extensive data. The method involves reverse engineering instructions from input-output pairs and applying these to test inputs. The research highlights the importance of self-supervised learning in understanding complex structures and demonstrates LLMs' capabilities in zero-shot and few-shot learning. It also explores chain-of-thought prompting for multi-step reasoning. The study underscores the role of human-like biases in learning and suggests improvements like multi-agent systems and memory usage for better performance, aiming to solve a majority of ARC tasks with GPT-4. </details> |
| [2023](https://aclanthology.org/W13-2322.pdf) | AMR (3.0) | Abstract Meaning Representation (Bank) | [![Conference](https://img.shields.io/badge/Conference-ACL'23-blue)](https://aclanthology.org/W13-2322.pdf) | [![Website](https://img.shields.io/badge/Website-AMR-red)](https://amr.isi.edu/) | <details><summary>Summary</summary>Abstract Meaning Representation (AMR) is a semantic representation language capturing the essence of English sentences to advance natural language understanding and generation. It offers a unified format for semantically annotating sentences, inspired by the success of syntactic treebanks. AMR's graph-based structure, emphasizing readability and simplicity, abstracts from syntax to focus on meaning. Utilizing tools like a power editor and the 'smatch' script, AMR ensures consistent and efficient annotation. With an expanding AMR bank and applications in diverse areas including machine translation, AMR is poised to significantly impact the field, driving future research and practical applications in natural language processing. </details> |
| [2023](https://doi.org/10.35111/44cy-bp51) | AMR (3.0) | Abstract Meaning Representation (AMR) Annotation Release 3.0 | [![Conference](https://img.shields.io/badge/Conference-Related'23-blue)](https://doi.org/10.35111/44cy-bp51) | [![LDC Catalog](https://img.shields.io/badge/LDC_Catalog-Website-red)](https://catalog.ldc.upenn.edu/LDC2020T02) | <details><summary>Summary</summary>Abstract Meaning Representation (AMR) Annotation Release 3.0, developed by Linguistic Data Consortium and partners, contains a sembank of over 59,255 English sentences from various sources for advancing natural language processing. This release enhances quality, adds annotations, and includes multi-sentence annotations. AMR represents sentence meanings as graphs, abstracting from syntax to focus on semantic structure. The data, sourced from diverse programs and including new text types, is split into training, development, and test partitions. This release is part of ongoing efforts to enrich machine translation and other applications through improved semantic understanding. /details> |
| [2023](https://arxiv.org/abs/2301.10414) | Logic & Info | Towards a Unification of Logic and Information Theory | [![arXiv 2023](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2301.10414) | N/A | <details><summary>Summary</summary>This work explores the efficient transmission of logical statements, innovatively connecting logic and information theory. It treats logical statements as equivalent if they lead to the same deductions, applying rate-distortion theory for communication. Using propositional logic modelled as polynomial equations in finite fields, it investigates various scenarios, including transmissions with and without pre-existing background statements. Key contributions include demonstrating the optimality of incremental communications and the surprising "less is more" theorems. The study also delves into the partition compression problem, providing theoretical bounds and proposing linear codes for practical implementation, achieving asymptotic optimality under certain conditions. </details> |
| [2023](https://arxiv.org/abs/2312.12891) | MinePlnr | Benchmark for long-horizon planning in Minecraft worlds | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2312.12891) | [![GitHub](https://img.shields.io/github/stars/IretonLiu/mine-pddl.svg?style=social)](https://github.com/IretonLiu/mine-pddl/) | <details><summary>Summary</summary> MinePlanner introduces a benchmark for testing AI planning capabilities in large, complex Minecraft worlds. Comprising 45 tasks with escalating difficulty, it assesses planners' abilities to navigate environments dense with objects, many of which are irrelevant to task goals. The benchmark challenges current planners, including Fast Downward and ENHSP-20, revealing significant limitations in handling large-domain problems. MinePlanner highlights the need for advancements in planning algorithms to cope with real-world scales and complexity. This framework not only serves as a testbed for AI planning research but also aims to foster collaboration between the learning and planning sectors in AI. </details> |
| [2023](https://openreview.net/forum?id=PgDbFx9bk8) | GenPlan23 | Abstract world models for value-preserving planning | [![Paper](https://img.shields.io/badge/Paper-2023-blue)](https://openreview.net/forum?id=PgDbFx9bk8) | N/A | <details><summary>Summary</summary> Learning Abstract World Models for Value-preserving Planning by Rafael Rodriguez-Sanchez and George Konidaris explores the development of abstract Markov Decision Processes (MDPs) for advanced planning in reinforcement learning. The paper addresses the challenge of complex decision-making in general-purpose agents by proposing state and action abstractions within abstract MDPs. This approach ensures effective planning and decision-making while maintaining compatibility with specific tasks. By leveraging information maximization and deep learning methods, the paper demonstrates improved planning efficiency in various environments. The research contributes significantly to the field by blending theoretical and empirical insights for effective abstract model learning and planning. </details> |
| [2023](https://openreview.net/forum?id=PjYUlfpLJE) | D3A | Building long-term 3D semantic maps | [![Paper](https://img.shields.io/badge/Paper-2023-blue)](https://openreview.net/forum?id=PjYUlfpLJE) | [![GitHub](https://img.shields.io/github/stars/IfrahIdrees/D3A.svg?style=social)](https://github.com/IfrahIdrees/D3A) | <details><summary>Summary</summary>Introduces an algorithm for building dynamic 3D semantic maps, crucial for household robots in unstructured environments.</details> |
| [2023](https://www.ijcai.org/proceedings/2023/0839.pdf) | Plansformer tool | Plansformer Tool: Demonstrating Generation of Symbolic Plans Using Transformers | [![Paper](https://img.shields.io/badge/Paper-2023-blue)](https://www.ijcai.org/proceedings/2023/0839.pdf) | N/A | <details><summary>Summary</summary>"Plansformer Tool: Demonstrating Generation of Symbolic Plans Using Transformers" introduces Plansformer, a novel AI tool leveraging transformer-based language models to generate symbolic plans. Fine-tuned on classical planning domains, Plansformer demonstrates effective plan generation, evaluated through metrics like ROUGE and BLEU, and validated for optimality. It surpasses other models in generating valid plans for simple domains but faces challenges in more complex scenarios. Offering a user-friendly web interface, Plansformer enhances planning efficiency in diverse fields. The research opens new pathways for utilizing large language models in symbolic domains, signifying a step forward in AI planning technologies. </details> |
| [2022](https://proceedings.neurips.cc/paper_files/paper/2022/hash/d0241a0fb1fc9be477bdfde5e0da276a-Abstract-Conference.html) | compositional generalisation | Compositional generalization through abstract representations in human and artificial neural networks | [![Paper](https://img.shields.io/badge/Paper-2022-blue)](https://proceedings.neurips.cc/paper_files/paper/2022/hash/d0241a0fb1fc9be477bdfde5e0da276a-Abstract-Conference.html) | N/A | <details><summary>Summary</summary>This study explores compositional generalization in humans and artificial neural networks (ANNs) through a highly compositional task. By examining human behavior and neural correlates using fMRI, it identifies behavioral patterns of compositional generalization. The study also incorporates pretraining paradigms in ANNs, embedding prior knowledge of the task to improve performance. Results indicate that pretraining induces abstract internal representations in ANNs, leading to enhanced generalization and learning efficiency. It also reveals a content-specific topography of abstract representations across the human cortex. This research provides empirical evidence for the role of abstract representations in compositional generalization, with implications for ANN design and training. </details> |
| [2022](https://arxiv.org/abs/2212.08681) | Plansformer | Plansformer: Generating Symbolic Plans using Transformers | [![arXiv](https://img.shields.io/badge/arXiv-2022-brightgreen)](https://arxiv.org/abs/2212.08681) | N/A | <details><summary>Summary</summary>Introduces Plansformer, an LLM fine-tuned on planning problems, demonstrating high performance in various planning domains.</details> |
| [2022](https://arxiv.org/abs/2211.08451) | Kogito | A Knowledge-Grounded Neural Conversational Model | [![arXiv](https://img.shields.io/badge/arXiv-2022-brightgreen)](https://arxiv.org/abs/2211.08451) | [![GitHub](https://img.shields.io/github/stars/epfl-nlp/kogito.svg?style=social)](https://github.com/epfl-nlp/kogito) | <details><summary>Summary</summary>"kogito" by Mete Ismayilzada and Antoine Bosselut is an innovative toolkit designed to generate commonsense knowledge inferences from textual input. It integrates with natural language generation models, offering a customizable and extensible interface for inference generation. The toolkit includes a library of pre-trained models like GPT-2, GPT-3, and COMET, and features modules for head extraction, relation matching, and inference filtering. kogito allows users to define custom knowledge relations, enhancing its adaptability. Accompanied by extensive documentation, the tool aims to standardize and simplify the process of generating meaningful commonsense inferences, paving the way for more intelligent and context-aware AI systems. </details> |
| [2022](https://ieeexplore.ieee.org/document/9488275) | RoboCat | A Category Theoretic Framework for Robotic Interoperability Using Goal-Oriented Programming | [![IEEE](https://img.shields.io/badge/Conference-IEEE'22-blue)](https://ieeexplore.ieee.org/document/9488275) | N/A | <details><summary>Summary</summary> RoboCat, developed by Angeline Aguinaldo and colleagues, introduces a novel framework for robotic programming, leveraging category theory for enhanced interoperability and usability. It transforms the way robots are programmed by adopting a goal-oriented, declarative approach that utilizes high-level abstractions rather than focusing on low-level, vendor-specific programming. By defining hierarchical interfaces and using mathematical representations, RoboCat simplifies integrating new hardware and software into robotic systems. This framework not only eases the programming process but also ensures consistency across different robotic platforms, making it a significant step towards more adaptable and efficient robotic applications in various industries. </details> |
| [2022](https://arxiv.org/abs/2203.15827) | LinkBERT | Pretraining Language Models with Document Links | [![arXiv 2022](https://img.shields.io/badge/arXiv-2022-brightgreen)](https://arxiv.org/abs/2203.15827) | [![Star](https://img.shields.io/github/stars/michiyasunaga/LinkBERT.svg?style=social)](https://github.com/michiyasunaga/LinkBERT) | <details><summary>Summary</summary>"LinkBERT: Pretraining Language Models with Document Links" by Michihiro Yasunaga, Jure Leskovec, and Percy Liang proposes a novel pretraining approach for language models, utilizing document links to capture inter-document relationships. LinkBERT, by integrating these links, effectively enhances language understanding and reasoning capabilities, especially in tasks requiring multi-hop reasoning and document relation comprehension. Tested in both general and biomedical domains, LinkBERT demonstrates notable improvements over traditional models like BERT, particularly in complex tasks and few-shot learning scenarios. This approach sets new benchmarks in biomedical NLP tasks, showcasing the immense potential of document-link-based pretraining in language models. </details> |
| [2021](https://arxiv.org/abs/2109.12240) | LCN | Logical Credal Networks | [![arXiv 2021](https://img.shields.io/badge/arXiv-2021-brightgreen)](https://arxiv.org/abs/2109.12240) | [![Star](https://img.shields.io/github/stars/radum2275/crema.svg?style=social)](https://github.com/radum2275/crema) | <details><summary>Summary</summary> "Logical Credal Networks" by Haifeng Qian et al. presents a novel approach to probabilistic logic modeling, addressing the challenge of representing imprecise information in AI applications. LCNs allow for the use of arbitrary logic formulas with probability bounds, overcoming the limitations of traditional models in expressiveness and dependency representation. Featuring a unique Markov condition, LCNs can manage cyclic dependencies, making them versatile for real-world scenarios like Mastermind puzzles and credit card fraud detection. The experimental results demonstrate LCNs' superiority in aggregating diverse information sources, marking a significant advancement in probabilistic logic models and their application in uncertain environments. </details> |
| [2021](https://arxiv.org/abs/2106.12574) | DeepStochLog | Neural Stochastic Logic Programming | [![arXiv 2021](https://img.shields.io/badge/arXiv-2021-brightgreen)](https://arxiv.org/abs/2106.12574) | [![Star](https://img.shields.io/github/stars/ML-KULeuven/deepstochlog.svg?style=social)](https://github.com/ML-KULeuven/deepstochlog) | <details><summary>Summary</summary> "DeepStochLog: Neural Stochastic Logic Programming" introduces a novel framework that combines neural networks with stochastic logic programming, offering a scalable and expressive approach to neural-symbolic computation. DeepStochLog enhances traditional logic programming with neural networks, improving its capabilities in complex tasks such as MNIST Digit Addition and Handwritten Mathematical Expressions. The framework not only demonstrates state-of-the-art performance in various neural-symbolic tasks but also excels in scalability and efficiency. DeepStochLog's ability to encode complex relational problems beyond standard grammars opens new possibilities in AI, highlighting its significance in advancing neural-symbolic integration. </details> |
| [2021](https://arxiv.org/abs/2104.08400) | Structure-aware-BART | Structure-Aware Abstractive Conversation Summarization via Discourse and Action Graphs | [![arXiv 2021](https://img.shields.io/badge/arXiv-2021-brightgreen)](https://arxiv.org/abs/2104.08400) | [![Star](https://img.shields.io/github/stars/SALT-NLP/Structure-Aware-BART.svg?style=social)](https://github.com/SALT-NLP/Structure-Aware-BART) | <details><summary>Summary</summary> "Structure-Aware Abstractive Conversation Summarization via Discourse and Action Graphs" by Jiaao Chen and Diyi Yang introduces an innovative summarization model that integrates discourse relations and action graphs into conversation summaries. The model addresses the unstructured and complex nature of human conversations, improving the preciseness of summaries. By constructing discourse relation graphs and action graphs, the model effectively captures dependencies between utterances and associations between speakers and actions. Empirical tests show significant improvements over existing methods in both automated and human evaluations. This approach opens new avenues for accurate and informative conversation summarization in various domains. </details> |
| [2021](https://www.sciencedirect.com/science/article/pii/S2352711021001126) | 2P-Kt | A logic-based ecosystem for symbolic AI | [![ScienceDirect](https://img.shields.io/badge/Conference-ScienceDirect'21-blue)](https://www.sciencedirect.com/science/article/pii/S2352711021001126) | [![Star](https://img.shields.io/github/stars/tuProlog/2p-kt.svg?style=social)](https://github.com/tuProlog/2p-kt), [![Pika-Lab](https://img.shields.io/badge/Website-Pika--Lab-red)](https://pika-lab.gitlab.io/tuprolog/2p-kt-web/) | <details><summary>Summary</summary> "2P-Kt: A logic-based ecosystem for symbolic AI" by Giovanni Ciatto et al., presents 2P-Kt, a significant evolution of the tuProlog project, aimed at creating an open, modular, and interoperable ecosystem for logic programming and symbolic AI. 2P-Kt leverages Kotlin multiplatform technology, offering a wide range of functionalities such as logic term manipulation, unification, and solver engines. It supports different logic programming paradigms and facilitates the integration of symbolic and sub-symbolic AI. The platform is designed to be extensible, encouraging further developments in AI research and applications. 2P-Kt's open-source nature and comprehensive toolkit make it a valuable asset for both researchers and practitioners in AI. </details> |
| [2020](https://arxiv.org/abs/1908.05646) | SenseBERT | Driving Some Sense into BERT | [![arXiv 2020](https://img.shields.io/badge/arXiv-2020-brightgreen)](https://arxiv.org/abs/1908.05646) | [![Star](https://img.shields.io/github/stars/AI21Labs/sense-bert.svg?style=social)](https://github.com/AI21Labs/sense-bert) | <details><summary>Summary</summary> SenseBERT, an extension of BERT, introduces a novel approach to lexical semantics by incorporating word sense information directly into the pre-training process. Using WordNet's supersense categories for weak-supervision, it enhances BERT's capability to understand and predict word meanings in context. This results in significantly improved performance on lexical tasks like Word Sense Disambiguation and the Word in Context (WiC) task, while maintaining competitive performance on standard benchmarks like GLUE. The model effectively manages word ambiguity and out-of-vocabulary words, showing potential for richer semantic learning in language models without relying on human-annotated data. SenseBERT represents a significant advancement in harnessing external linguistic knowledge sources for neural language models. </details> |
| [2019](https://arxiv.org/abs/1905.06088) | CILP | Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning | [![arXiv 2019](https://img.shields.io/badge/arXiv-2019-brightgreen)](https://arxiv.org/abs/1905.06088) | N/A | <details><summary>Summary</summary> "Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning" outlines an approach that merges neural network-based learning with symbolic logic-based reasoning, addressing the interpretability and accountability issues in AI. It covers different strategies for representing symbolic knowledge in neural networks and discusses the integration of various logic types for robust reasoning and learning. The paper highlights the importance of explainable AI, focusing on knowledge extraction, natural language generation, and program synthesis. It presents neural-symbolic learning and reasoning as key to developing intelligent systems that are not only efficient and effective but also interpretable and accountable. </details> |
| [2019](https://arxiv.org/abs/1910.13461) | BART (Meta) | Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension | [![arXiv 2019](https://img.shields.io/badge/arXiv-2019-brightgreen)](https://arxiv.org/abs/1910.13461) | [![Star](https://img.shields.io/github/stars/facebookresearch/bart_ls.svg?style=social)](https://github.com/facebookresearch/bart_ls) | <details><summary>Summary</summary> "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension" introduces BART, a denoising autoencoder that pre-trains sequence-to-sequence models by corrupting and reconstructing text. It employs a Transformer-based architecture, combining aspects of BERT and GPT. BART's flexible noising strategy includes token masking, deletion, and text infilling, making it versatile for various tasks. It excels in text generation, comprehension tasks, and machine translation, matching or surpassing benchmark performances like RoBERTa's on GLUE and SQuAD. Ablation studies within the BART framework indicate its consistency across tasks. BART's scalability in pre-training shows significant potential for wide applications in natural language processing. </details> |
| [2018](https://arxiv.org/abs/1805.10872) | DeepProbLog | Neural Probabilistic Logic Programming | [![arXiv 2018](https://img.shields.io/badge/arXiv-2018-brightgreen)](https://arxiv.org/abs/1805.10872) | [![Star](https://img.shields.io/github/stars/ML-KULeuven/deepproblog.svg?style=social)](https://github.com/ML-KULeuven/deepproblog), [![DTAI](https://img.shields.io/badge/Website-DTAI-red)](https://dtai.cs.kuleuven.be/problog/) | <details><summary>Summary</summary> DeepProbLog introduces a novel approach to neural probabilistic logic programming, effectively integrating deep learning with probabilistic reasoning. It extends the probabilistic logic programming language ProbLog with neural predicates, handling uncertainty from neural network outputs within a logical reasoning framework. The language supports both symbolic and subsymbolic reasoning, allowing end-to-end model training on complex tasks that require more than just standard learning. Through gradient descent-based learning, DeepProbLog jointly trains parameters in logic programs and neural networks. This integration leverages the strengths of both neural networks and logical reasoning, making DeepProbLog a powerful tool for advanced artificial intelligence applications.  </details> |
| [2018](http://proceedings.mlr.press/v80/xu18h.html) | Sem-Loss Sym-Knowledge | A Semantic Loss Function for Deep Learning with Symbolic Knowledge | [![Conference](https://img.shields.io/badge/Conference-ML'18-blue)](http://proceedings.mlr.press/v80/xu18h.html) | [![Star](https://img.shields.io/github/stars/npepperUQLab/Knowledge-Based-Neural-Network-.svg?style=social)](https://github.com/npepperUQLab/Knowledge-Based-Neural-Network-) | <details><summary>Summary</summary> "A Semantic Loss Function for Deep Learning with Symbolic Knowledge" introduces a novel approach to integrate deep learning with symbolic logic through a semantic loss function. This function evaluates the conformity of neural network outputs to logical constraints, enhancing learning in both semi-supervised and structured prediction tasks. The method demonstrates significant improvements in classification accuracy on datasets like MNIST and CIFAR-10. It is particularly effective in complex structured prediction, such as preference rankings or path predictions. The semantic loss function is developed axiomatically, ensuring logical soundness and differentiability, and can be incorporated into standard deep learning models as an additional regularization term.  </details> |
| [2018](https://arxiv.org/abs/1810.04805) | BERT (Google) | Pre-training of Deep Bidirectional Transformers for Language Understanding | [![arXiv 2018](https://img.shields.io/badge/arXiv-2018-brightgreen)](https://arxiv.org/abs/1810.04805) | [![Star](https://img.shields.io/github/stars/google-research/bert.svg?style=social)](https://github.com/google-research/bert) | <details><summary>Summary</summary> BERT is a transformative language representation model that pre-trains deep bidirectional representations from the unlabeled text by considering the context from both sides of a token in all layers. This novel approach enables it to achieve remarkable results in eleven NLP tasks, surpassing existing benchmarks significantly. BERT operates through two pre-training tasks: masked LM and next sentence prediction, facilitating effective language model pre-training. Its architecture is a multi-layer bidirectional Transformer encoder, capable of handling both single and paired text inputs. This versatility, combined with minimal architectural adjustments for various downstream tasks, makes BERT exceptionally powerful and adaptable for a wide range of NLP applications. </details> |
| [2017](https://paperswithcode.com/task/amr-parsing) | AMR Parsing | Transition-based Neural Parser | [![Resource](https://img.shields.io/badge/Resource-PapersWithCode'23-blue)](https://paperswithcode.com/task/amr-parsing) | [![Star](https://img.shields.io/github/stars/IBM/transition-amr-parser.svg?style=social)](https://github.com/IBM/transition-amr-parser) | <details><summary>Summary</summary>This paper introduces a novel, efficient approach to parsing Abstract Meaning Representation (AMR) through an incremental, transition-based parser. Adapting techniques from dependency parsing, it addresses unique AMR challenges like non-projectivity, reentrancy, and complex word-to-node alignments. The parser processes sentences left-to-right in linear time, enhancing efficiency. The proposed evaluation metrics assess specific sub-tasks, providing deeper insights into parser performance across various aspects, including named entity recognition and negation handling. The parser shows competitive results, particularly in recovering named entities, despite not achieving the highest overall Smatch score, showcasing the potential for real-time applications and studies in building sentence meaning incrementally. </details> |
| [2014](https://content.iospress.com/articles/intelligenza-artificiale/ia106) | cplint | A framework for reasoning with Probabilistic Logic Programming | [![iris](https://img.shields.io/badge/IRIS-2014-Blue)](https://iris.unife.it/bitstream/11392/2368375/8/2017.riguzzi.cplint%20on%20SWISH_POST%20PRINT.pdf) | [![GitHub](https://img.shields.io/github/stars/friguzzi/cplint.svg?style=social)](https://github.com/friguzzi/cplint)  [![cplint](https://img.shields.io/badge/cplint-Website-red)](https://cplint.ml.unife.it/) | <details><summary>Summary</summary> "cplint on SWISH" is a cutting-edge web application enabling probabilistic logical inference directly in a web browser. It significantly simplifies user interaction by obviating the need for complex installations. The platform supports advanced features such as hybrid programs with both discrete and continuous variables, a unique offering in web-based probabilistic logic programming. It includes various inference algorithms like rejection sampling and Metropolis-Hasting for robust reasoning. Notably user-friendly, it provides a diverse array of examples across different probabilistic models, demonstrating the system's versatility and capability. Future enhancements promise to expand its functionalities, making it an increasingly powerful tool for probabilistic programming. </details> |
| [2007](https://www.sciencedirect.com/science/article/pii/S030439750600750X) | Modal | Connectionist modal logic: Representing modalities in neural networks | [![ScienceDirect](https://img.shields.io/badge/Conference-ScienceDirect'07-blue)](https://www.sciencedirect.com/science/article/pii/S030439750600750X) | [![Star](https://img.shields.io/github/stars/rkirsling/modallogic.svg?style=social)](https://github.com/rkirsling/modallogic) | <details><summary>Summary</summary> The paper "Connectionist Modal Logic: Representing Modalities in Neural Networks" introduces a novel framework that integrates neural networks and modal logic, referred to as Connectionist Modal Logic (CML). This approach is part of the broader domain of neural-symbolic integration, aiming to utilize symbolic knowledge within the neurocomputing paradigm. CML facilitates the representation and learning of propositional modal logic using neural networks. The framework is validated through the application to the Muddy Children Puzzle, demonstrating its potential in distributed knowledge representation. The paper suggests that CML offers a balance between expressive power and computational feasibility and hints at the possibility of extending beyond propositional logic to first-order logic. </details> |
| [2003](https://ieeexplore.ieee.org/document/1200733) | DAMLJessKB | A Tool for Reasoning with the Semantic Web | [![IEEE](https://img.shields.io/badge/Conference-IEEE'03-blue)](https://ieeexplore.ieee.org/document/1200733) | N/A | <details><summary>Summary</summary>"DAMLJessKB: A Tool for Reasoning with the Semantic Web" by Joseph Kopena and William C. Regli presents DAMLJessKB, an innovative tool designed for reasoning with Semantic Web technologies. The tool focuses on integrating Semantic Web standards like DAML for effective knowledge management and inference in domains such as engineering design. Using the Jess production system, DAMLJessKB interprets and processes RDF/DAML encoded data, enabling sophisticated reasoning capabilities, including class instance and terminological reasoning. The tool's practical applications, ease of integration, and potential enhancements to support OWL, make it a significant step towards realizing the Semantic Web vision. </details> |


## Knowledge representation major projects

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2023](https://arxiv.org/abs/2305.06349) | ReckonMK | Reckoning MetaKG: Hyper-Edge Prediction in the Meta Knowledge Graph | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2305.06349) | [![GitHub](https://img.shields.io/github/stars/eric11eca/reckoning-metakg.svg?style=social)](https://github.com/eric11eca/reckoning-metakg) | <details><summary>Summary</summary>RECKONING introduces an innovative approach to enhance the reasoning abilities of transformer-based language models. It encodes contextual knowledge directly into the model's parameters using a bi-level optimization process, consisting of an inner loop for rapid adaptation and an outer loop for optimizing initial weights. This method improves robustness against distractors and enhances reasoning performance. Extensive testing on datasets like ProofWriter, CLUTRR-SG, and FOLIO shows that RECKONING outperforms traditional in-context reasoning, particularly in handling irrelevant facts and generalizing to longer reasoning chains and real-world knowledge. Additionally, it proves more efficient in scenarios involving multiple questions due to its single-time knowledge encoding.</details> |
| [2023](https://arxiv.org/abs/2305.02364) |  PeaCok |  Persona Commonsense Knowledge for Consistent and Engaging Narratives  | [![arXiv ](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2305.02364) |  [![GitHub](https://img.shields.io/github/stars/Silin159/PeaCoK.svg?style=social)](https://github.com/Silin159/PeaCoK) | <details><summary>Summary</summary>  PEACOK is a novel knowledge graph offering comprehensive persona commonsense knowledge to enhance narrative systems. Containing around 100K human-validated facts across five key dimensions, it was constructed using a combination of existing commonsense knowledge graphs and inputs from large-scale language models, refined through a human-AI majority voting process. This resource provides deep persona insights, fostering more consistent and engaging narratives in applications such as dialogue systems. While showcasing the potential of integrating machine-generated and human-validated content, PEACOK also acknowledges its linguistic and ethical limitations, primarily its focus on English data and reliance on existing knowledge sources. v</details> |
| [2023](https://bair.berkeley.edu/blog/2023/04/03/koala/) | KOALA | A Dialogue Model for Academic Research | [![BAIR Blog](https://img.shields.io/badge/Website-BAIR%20Blog-red)](https://bair.berkeley.edu/blog/2023/04/03/koala/) (blog post only) |  [![GitHub](https://img.shields.io/github/stars/young-geng/EasyLM.svg?style=social)](https://github.com/young-geng/EasyLM/blob/main/docs/koala.md) | <details><summary>Summary</summary> Koala is a new dialogue model developed by fine-tuning Meta's LLaMA with web-gathered dialogue data, aiming to match the capabilities of larger closed-source models. Focusing on high-quality, diverse data including user-shared dialogues with ChatGPT, Koala demonstrates competitive performance, sometimes preferred over Stanford’s Alpaca and equaling ChatGPT in user studies. This suggests smaller, local models with carefully curated data can achieve results similar to larger ones, highlighting the importance of dataset quality over size. However, Koala, being a research prototype, has limitations in content, safety, and reliability and is recommended only for academic research. Koala's release includes an interactive demo, training framework, model weights, and a test set, intended for academic use under specific licenses. The project, a Berkeley AI Research Lab (BAIR) initiative, encourages community feedback to identify potential improvements and safety issues. </details> |
| [2023](https://www.wolfram.com/data-framework/) | Wolfram Alpha  | Wolfram Data Framework (WDF) Take data and make it meaningful | [![Documentation](https://img.shields.io/badge/Documentation-Wolfram'23-blue)](https://reference.wolfram.com/language/guide/WDFWolframDataFramework.html) | [![GitHub](https://img.shields.io/github/stars/WolframResearch.svg?style=social)](https://github.com/WolframResearch) | <details><summary>Summary</summary>  Wolfram Data Framework (WDF) utilizes the Wolfram Language and Knowledgebase for a standardized computable description of real-world data. It includes functions for importing, and interpreting data, and structures like Integer, Entity, Quantity, and CloudObject. WDF supports data representation in Lists, Associations, Datasets, and Graphs, with specific functions for managing custom entities and their permissions. </details> |
| [2023](https://www.newyorker.com/culture/infinite-scroll/your-ai-companion-will-support-you-no-matter-what#:~:text=Now%2C%20with%20A.I.,personalities%20according%20to%20users'%20desires.) | AI companions | Various approaches from various companies | N/A | [![Kindroid](https://img.shields.io/badge/Website-Kindroid-red)](https://kindroid.ai/) [![Nomi](https://img.shields.io/badge/Website-Nomi-red)](https://nomi.ai/) [![Character](https://img.shields.io/badge/Website-Character-red)](https://beta.character.ai/) | <details><summary>Summary</summary> AI companions like Kindroid AI, Nomi AI, and Character AI represent the evolving landscape of personalized digital assistants. Kindroid AI offers a customizable AI companion that can engage in text chat, provide AI selfies, and features human-like voices. It acts as a personal assistant, handling reminders and schedules while ensuring privacy and security of chats【27†source】. Nomi AI focuses on personalized conversations and emotional support, evolving through interactions to understand user preferences and styles, enhancing emotional bonds. It supports setting reminders and discussing a wide range of topics, underlining the role of AI in personal growth and mental health support【31†source】. Unfortunately, I couldn't retrieve specific information about Character AI. These platforms exemplify the trend towards more interactive, emotionally intelligent AI companions in daily life. </details> |
| [2023](https://arxiv.org/abs/2307.02628) | SKIP | Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference | [![arXiv 2023](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2307.02628) | [![GitHub](https://img.shields.io/github/stars/tuetschek/e2e-dataset.svg?style=social)](https://github.com/tuetschek/e2e-dataset) | <details><summary>Summary</summary> SkipDecode is an innovative token-level early exit method for large language models, enhancing efficiency in batch processing and KV caching. It overcomes limitations of existing methods by implementing unified exit points and a monotonically decreasing number of exits as sequences progress. This design optimizes batched inference and eliminates the need for recalculating KV caches. The method achieves substantial inference speedups (2x to 5x) with minimal performance loss. Tested on OPT models with extensive datasets, SkipDecode maintains a controlled computational budget and outperforms similar techniques. Future improvements may include alternative decay functions and policy extensions to prompts. </details> |
| [2023](https://arxiv.org/abs/2208.01174) | TextWorldExpress | Simulating Text Games at One Million Steps Per Second | [![arXiv 2023](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2208.01174) | [![CognitiveAI Lab](https://img.shields.io/badge/Website-CognitiveAI_Lab-red)](https://github.com/cognitiveailab/TextWorldExpress) [![Microsoft](https://img.shields.io/badge/Website-Microsoft-red)](https://github.com/microsoft/TextWorld) | <details><summary>Summary</summary> TEXTWORLDEXPRESS is a high-performance simulator that significantly advances text-based game simulations for virtual agent research. It dramatically increases simulation throughput to over one million steps per second, enabling complex billion-step experiments in about a day. This tool enhances agent evaluation in tasks requiring language understanding, problem-solving, and reasoning. It outperforms existing simulators like TextWorld and Jericho in speed, offering rapid simulations on standard desktop hardware. Although it has some limitations, such as requiring SCALA for new environment additions, its contribution as an open-source tool represents a significant leap forward in embodied agent research and text-based game simulations. </details> |
| [2023](https://github.com/facebookresearch/ParlAI) | ParlAI | Python framework for sharing, training and testing dialogue models, from open-domain chitchat | N/A (Meta) | [![GitHub](https://img.shields.io/github/stars/facebookresearch/ParlAI.svg?style=social)](https://github.com/facebookresearch/ParlAI), [![ParlAI](https://img.shields.io/badge/Website-ParlAI-red)](https://parl.ai/) | <details><summary>Summary</summary> ParlAI is a unified Python-based platform designed for dialogue AI research. It offers a one-stop shop for researchers with access to over 100 popular language datasets and a wide set of reference models, including pre-trained ones. Key features include seamless integration with Amazon Mechanical Turk and Facebook Messenger for data collection, training, and human evaluation. Originally open-sourced by Facebook in 2017, ParlAI supports various project domains like generative and retrieval models, interactive learning, and offensive language recognition. It allows training and evaluating dialogue models on diverse tasks and supports multi-modality for tasks involving both text and images. For more details, one can check ParlAI's GitHub repo, which includes installation guides, documentation, and examples. </details> |
| [2023](https://github.com/e-spaulding/xpo) | DWD overlay | The DARPA Wikidata Overlay | [![Paper](https://img.shields.io/badge/Conference-ISA'23-blue)](https://aclanthology.org/2023.isa-1.1.pdf) | [![GitHub](https://img.shields.io/github/stars/e-spaulding/xpo.svg?style=social)](https://github.com/e-spaulding/xpo) | <details><summary>Summary</summary> The DARPA Wikidata Overlay (DWD Overlay) is an enriched subset of Wikidata, integrated with PropBank roles to enhance natural language processing ontologies. It addresses Wikidata's entity-centric focus by adding detailed event and action descriptions, including temporal relations based on Allen Interval Temporal Logic. The overlay is accessible in JSON format, facilitating easy integration into various applications, particularly for event extraction and narrative understanding. The project involves aligning Wikidata's entity-oriented structure with PropBank's event-focused roles, presenting unique challenges. Future work includes fully integrating the overlay into Wikidata and expanding its scope and accuracy. </details> |
| [2023](https://aclanthology.org/2023.acl-demo.1/) | HITL-Schema | Human-in-the-Loop Schema Induction | [![arXiv 2023](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2302.13048) | [![GitHub](https://img.shields.io/github/stars/aclanthology/2023.acl-demo.1.svg?style=social)](https://aclanthology.org/2023.acl-demo.1/) | <details><summary>Summary</summary>  The Human-in-the-Loop Schema Induction system innovatively combines the capabilities of GPT-3.1 with human input to create detailed and accurate event schemas, crucial for event-centric natural language understanding (NLU). This approach overcomes the limitations of fully manual or automated systems by ensuring scalability and quality. The system's process involves step generation, node extraction, graph construction, and node grounding. Its interactive interface simplifies user involvement in schema editing and generation. While acknowledging the cultural biases inherent in the data and models used, the system aims for inclusive representation in diverse domains, enhancing tasks like misinformation detection and question answering. </details> |
| [2023](https://apps.dtic.mil/sti/trecms/pdf/AD1202435.pdf) | RAMFIS | REPRESENTATION OF VECTORS AND ABSTRACT MEANINGS FOR INFORMATION SYNTHESIS | [![Paper](https://img.shields.io/badge/Conference-Related'23-blue)](https://apps.dtic.mil/sti/trecms/pdf/AD1202435.pdf) | N/A (U.S. Air Force) | <details><summary>Summary</summary> The RAMFIS project, part of the AIDA program, aimed at improving multimodal information processing by synthesizing diverse data sources to identify contradictions and confirmations. Initial focus was on mapping multi-modal vector representations to the LDC's AIDA Ontology, later shifting to text vector representations. Key tasks included entity and event linking across documents, development of a cross-program ontology transitioning from the LDC Ontology to Wikidata, and enhancing coreference resolution using embedding-based methods. The project also involved face embedding mappings, exploring transformer embeddings, and error analysis using tools like Brandeis Explorer. Contributions from various teams were integral to achieving RAMFIS's multifaceted goals. </details> |
| [2022](https://arxiv.org/abs/2203.07540) | ScienceWorld | ScienceWorld: Is your Agent Smarter than a 5th Grader? | [![Paper](https://img.shields.io/badge/Paper-arXiv'22-brightgreen)](https://arxiv.org/abs/2203.07540) | [![GitHub](https://img.shields.io/github/stars/allenai/ScienceWorld.svg?style=social)](https://github.com/allenai/ScienceWorld) | <details><summary>Summary</summary>ScienceWorld is an interactive text-based environment designed to test AI agents' scientific reasoning skills at an elementary level. It features 30 benchmark tasks across various science topics, challenging agents to apply knowledge in a dynamic, procedural context. The environment, resembling a house with multiple rooms and objects, supports diverse actions and simulates processes like thermodynamics and electricity. Empirical tests reveal that current language models struggle with these tasks, indicating the need for better integration of declarative and procedural knowledge in AI. ScienceWorld's unique approach has broad implications for AI research, emphasizing the development of more advanced, reasoning-capable models. </details> |
| [2022](https://arxiv.org/abs/2210.07109) | D&D as a Dialogue | Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence | [![Paper](https://img.shields.io/badge/Paper-arXiv'22-brightgreen)](https://arxiv.org/abs/2210.07109) | N/A | <details><summary>Summary</summary> The study introduces Dungeons and Dragons (D&D) as an advanced AI challenge, emphasizing dialogue systems and interactive storytelling. Utilizing a comprehensive gameplay dataset, a large language model was trained to generate game dialogues and predict game states, effectively role-playing as characters or the Dungeon Master. The model's output was evaluated through human assessments, focusing on the authenticity and appeal of its dialogue. This research underscores AI's potential in complex, narrative-driven environments and marks a significant step in AI’s application in interactive storytelling, presenting both challenges and opportunities for future developments in the field of AI-driven narrative generation and game design. </details> |
| [2022](https://arxiv.org/abs/2202.00120) | QALD | QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia and Wikidata Translated by Native Speakers | [![Paper](https://img.shields.io/badge/Paper-arXiv'22-brightgreen)](https://arxiv.org/abs/2202.00120) | [![GitHub](https://img.shields.io/github/stars/ag-sc/QALD.svg?style=social)](https://github.com/ag-sc/QALD) | <details><summary>Summary</summary> QALD-9-plus, an enhancement of the QALD-9 dataset, introduces high-quality translations of questions into 8 languages, including several low-resource ones, and transfers SPARQL queries from DBpedia to Wikidata. This extension, done through native speakers and crowdsourcing, addresses flaws like poor translations and ambiguous questions, increasing the dataset's usability and relevance. It enables more comprehensive evaluation of KGQA systems, maintaining QALD-JSON format for ease of use. The project aims to further expand language coverage and question quantity, contributing significantly to the multilingual accessibility of KGQA systems and setting a benchmark for future KGQA research. </details> |
| [2022](https://machinelearning.apple.com/research/continuous-construction) | SAGA | A Platform for Continuous Construction and Serving of Knowledge At Scale | [![Paper](https://img.shields.io/badge/Paper-arXiv'22-brightgreen)](https://arxiv.org/abs/2204.07309) | [![Apple](https://img.shields.io/badge/Website-Apple-red)](https://machinelearning.apple.com/research/continuous-construction) | <details><summary>Summary</summary> Saga is a next-generation platform by Apple for constructing and serving knowledge graphs at an industrial scale. It continuously integrates data to create a central knowledge graph, addressing challenges like data freshness, accuracy, and provenance management. The platform uses a hybrid batch-incremental design and a federated polystore approach for diverse workloads, including a specialized graph query engine. Key features include live graph components for real-time data integration and graph machine learning for entity recognition and duplicate detection. Saga supports applications such as open-domain question answering and semantic annotations, continuously expanding and refining its knowledge base through collaborative efforts. </details> |
| [2022](https://www.ijcai.org/proceedings/2022/850) | Foresee | Knowledge-Based News Event Analysis and Forecasting Toolkit | [![Paper](https://img.shields.io/badge/Paper-IJCAI'22-blue)](https://www.ijcai.org/proceedings/2022/850) | N/A | <details><summary>Summary</summary>The toolkit presented is designed for knowledge-based analysis and forecasting of news events, powered by a Knowledge Graph (KG) developed from various sources. It retrieves ongoing news, identifies relevant events, and performs causal analysis to forecast potential outcomes. The toolkit maps news headlines to KG event types, uses causal knowledge extraction to enrich the graph, and includes event sequence analysis for comprehensive forecasting. Initially constructed from Wikidata, it focuses on significant societal events like disease outbreaks and natural disasters. The toolkit's interactive KG visualization aids in effective analysis, and a planned demonstration will showcase its capabilities using recent real-world events. </details> |
| [2021](https://arxiv.org/abs/2104.08811) | Human Schema | Human Schema Curation via Causal Association Rule Mining | [![Paper](https://img.shields.io/badge/Paper-arXiv'21-brightgreen)](https://arxiv.org/abs/2104.08811) | [![Links](https://img.shields.io/badge/Links-Inside_Paper-blue)](https://arxiv.org/abs/2104.08811) | <details><summary>Summary</summary>  Presents a semi-automatic system for curating a library of structured, machine-readable event schemas using Causal Association Rule Mining and a novel annotation interface, SchemaBlocks. This system produces 232 detailed event schemas, each defining a typical real-world scenario in terms of events, participants, and relationships. Combining automated script induction with human-driven annotation, the approach efficiently creates high-quality schemas. The schemas, rooted in the DARPA KAIROS Phase 1 ontology, are evaluated using a schema intrusion task and corpus coverage metric, demonstrating their coherence and broad applicability. The research contributes significantly to structured knowledge representation, releasing these resources for public use. </details> |
| [2021](https://arxiv.org/abs/2101.00297) | Few Shot Comet | Analyzing Commonsense Emergence in Few-shot Knowledge Models | [![arXiv](https://img.shields.io/badge/arXiv-2021-brightgreen)](https://arxiv.org/abs/2101.00297) | [![GitHub](https://img.shields.io/github/stars/allenai/few-shot-comet.svg?style=social)](https://github.com/allenai/few-shot-comet) | <details><summary>Summary</summary> The study "Analyzing Commonsense Emergence in Few-shot Knowledge Models" examines the emergence of commonsense knowledge in language models (LMs) fine-tuned on knowledge graph (KG) tuples. It questions whether commonsense knowledge is inherent from pretraining or acquired during fine-tuning. Through few-shot training settings, the study finds that commonsense knowledge models adapt rapidly from limited examples, suggesting pretraining provides an encoded knowledge base, with fine-tuning forming an interface to this knowledge. The research identifies key shifts in the model's attention heads and less change in feed-forward networks, indicating an adaptation in processing knowledge rather than changing stored representations. </details> |
| [2021](https://par.nsf.gov/servlets/purl/10288899) | UMR | Uniform Meaning Representation | [![Paper](https://img.shields.io/badge/Paper-NSF-blue)](https://par.nsf.gov/servlets/purl/10288899) | [![Web](https://img.shields.io/badge/Web-UMR4NLP-red)](https://umr4nlp.github.io/web/index.html), [![Tutorials (LREC)](https://img.shields.io/badge/Tutorials-LREC'21-red)](https://lrec2022.lrec-conf.org/en/workshops-and-tutorials/tutorials-details/), [![Tutorials (EMNLP)](https://img.shields.io/badge/Tutorials-EMNLP'21-red)](https://2022.emnlp.org/program/tutorials/) | <details><summary>Summary</summary> Uniform Meaning Representation (UMR) integrates and extends Abstract Meaning Representation (AMR) for annotating text semantics, emphasizing cross-linguistic application, including morphologically complex and low-resource languages. UMR extends AMR's capabilities by adding document-level features such as coreference and temporal relations. It supports both logical and lexical inference for enhanced semantic interpretation. Designed for scalability and ease of annotation, UMR is positioned to be universally applicable, adaptable to linguistic diversity, and suitable for large-scale applications. Pilot experiments indicate its robustness and reliability. Future developments include creating comprehensive annotation guidelines and tools to facilitate application across a wide range of languages. </details> |
| [2021](https://www.akbc.ws/2021/papers/4TpJpZ-_gyl) | LLM Knowledge from Analogy | Combining Analogy with Language Models for Knowledge Extraction | [![Paper](https://img.shields.io/badge/Paper-AKBC'21-blue)](https://openreview.net/forum?id=4TpJpZ-_gyl) | [![GitHub](https://img.shields.io/github/stars/dnr2/analogical-ke.svg?style=social)](https://github.com/dnr2/analogical-ke) | <details><summary>Summary</summary> The study introduces Analogical Knowledge Extraction (AKE), a novel method combining BERT Language Model with analogical reasoning for extracting structured knowledge from text. Aimed at expanding knowledge bases with type-leveled general knowledge, AKE uses semantic parsing to create query cases that link sentence semantics to knowledge base facts. It features an ontological scoring system combined with BERT-based fact classification to ensure accuracy and relevance of extracted facts. Evaluated on Simple English Wikipedia, AKE outperforms baselines like T5 and Relation Extraction models. Future directions include processing more data and exploring richer knowledge representations and query case properties for enhancing general-purpose AI systems. </details> |
| [2021](https://makg.org/) | MAKG/MS Satori |  Microsoft Academic Knowledge Graph / Satori project  | [![Web](https://img.shields.io/badge/Web-MAKG/MS-red)](https://makg.org/) [![Academic Webpage](https://img.shields.io/badge/Academic_Webpage-Microsoft-red)](https://www.microsoft.com/en-us/research/project/academic/) | [![GitHub](https://img.shields.io/github/stars/michaelfaerber/MAG2RDF.svg?style=social)](https://github.com/michaelfaerber/MAG2RDF) | <details><summary>Summary</summary> The Microsoft Academic Knowledge Graph (MAKG) is a large RDF dataset with over eight billion triples, offering comprehensive information on scientific publications and related entities like authors, institutions, journals, and fields of study. Originating from the Microsoft Academic Graph, it's licensed under the Open Data Attributions license. Key features include periodically updated RDF dumps, URI resolution within the Linked Open Data framework, a public SPARQL endpoint, HTML page descriptions via pubby, and entity embeddings for all 210M scientific papers. MAKG supports various applications, such as entity-centric exploration, data integration using RDF, and data analysis for knowledge discovery in the academic domain. </details> |
| [2020](https://ojs.aaai.org/index.php/AAAI/article/view/16792) | Comet Atomic | A Commonsense Knowledge Base for Modeling Atomic Events | [![arXiv](https://img.shields.io/badge/arXiv-2020-brightgreen)](https://ojs.aaai.org/index.php/AAAI/article/view/16792) [![Paper](https://img.shields.io/badge/Paper-arXiv'20-brightgreen)](https://arxiv.org/abs/2010.05953) | [![GitHub](https://img.shields.io/github/stars/allenai/comet-atomic-2020.svg?style=social)](https://github.com/allenai/comet-atomic-2020) | <details><summary>Summary</summary> (COMET-)ATOMIC2020, a new commonsense knowledge graph (CSKG), addresses the quality and coverage challenges in existing CSKGs by integrating symbolic commonsense knowledge with neural language models. It emphasizes that manually constructed CSKGs might not achieve the necessary coverage for all NLP scenarios and proposes a new evaluation framework focusing on the effectiveness of KGs in aiding language models to learn implicit knowledge representations. ATOMIC2020, containing unique general-purpose commonsense knowledge, outperforms other CSKGs in training knowledge models for new entities and events. Notably, a BART-based model trained on ATOMIC2020 surpasses GPT-3 in few-shot tasks, validated by human evaluation. </details> |
| [2020](https://arxiv.org/abs/2010.03790) | TWC | Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines | [![Paper](https://img.shields.io/badge/Paper-arXiv'20-brightgreen)](https://arxiv.org/abs/2010.03790) | [![GitHub](https://img.shields.io/github/stars/IBM/commonsense-rl.svg?style=social)](https://github.com/IBM/commonsense-rl) | <details><summary>Summary</summary> TextWorld Commonsense (TWC) is a novel environment for evaluating text-based Reinforcement Learning (RL) agents using commonsense knowledge. TWC challenges agents with tasks like house organization, requiring understanding of object properties and relationships, sourced from ConceptNet. Agents dynamically construct a commonsense graph, integrating this knowledge with game context for decision-making. Benchmarking against human performance indicates significant potential for agent improvement. TWC's games, varying in difficulty, test agents’ adaptability and efficiency. Empirical results confirm that commonsense-enhanced agents surpass text-only counterparts, positioning TWC as a valuable platform for advancing research in RL and commonsense reasoning in AI. </details> |
| [2020](https://arxiv.org/abs/2012.01707) | KBQA (IBM) | Leveraging Abstract Meaning Representation for Knowledge Base Question Answering | [![Paper](https://img.shields.io/badge/Paper-arXiv'20-brightgreen)](https://arxiv.org/abs/2012.01707) | [![GitHub](https://img.shields.io/github/stars/IBM/kbqa-relation-linking.svg?style=social)](https://github.com/IBM/kbqa-relation-linking) | <details><summary>Summary</summary> The paper presents Neuro-Symbolic Question Answering (NSQA), a modular KBQA system that leverages Abstract Meaning Representation (AMR) for understanding complex questions in natural language. NSQA uses AMR for parsing questions, graph transformation to create logical queries aligned with the knowledge base, and Logical Neural Networks (LNN) for reasoning over these queries. It successfully tackles challenges like n-ary argument mismatches and structural discrepancies between AMR and KB queries. NSQA achieves state-of-the-art performance on DBpedia-based datasets, demonstrating its ability to handle complex multi-hop questions and unusual expressions. This system reduces the need for end-to-end training datasets, making it a significant contribution to the field of KBQA. </details> |
| [2020](https://aclanthology.org/2020.acl-main.120/) | WCEP | A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal | [![Paper](https://img.shields.io/badge/Paper-ACL'20-blue)](https://aclanthology.org/2020.acl-main.120/) | [![GitHub](https://img.shields.io/github/stars/complementizer/wcep-mds-dataset.svg?style=social)](https://github.com/complementizer/wcep-mds-dataset) | <details><summary>Summary</summary> The WCEP dataset, leveraging the Wikipedia Current Events Portal, is a significant contribution to multi-document summarization (MDS). It comprises 10200 clusters of news articles, each with a concise, human-written summary. Unique in its scale, it expands each event's coverage by including additional relevant articles from the Common Crawl archive. This large-scale dataset is specifically designed for real-world applications like news aggregation and summarization. Through empirical evaluations using various state-of-the-art MDS methods, the dataset provides a robust platform for further research. Its realism and comprehensive approach distinguish it from existing MDS datasets, making it a valuable resource for advancing automatic summarization technologies. </details> |
| [2019](https://www.darpa.mil/program/knowledge-directed-artificial-intelligence-reasoning-over-schemas) | KAIROS | Knowledge-directed Artificial Intelligence Reasoning Over Schemas | N/A | [![DARPA](https://img.shields.io/badge/DARPA-KAIROS-red)](https://www.darpa.mil/program/knowledge-directed-artificial-intelligence-reasoning-over-schemas) | <details><summary>Summary</summary> The Knowledge-directed Artificial Intelligence Reasoning Over Schemas (KAIROS) program, led by Dr. Wil Corvey at the Defense Advanced Research Projects Agency (DARPA), aims to develop AI systems that can rapidly comprehend world events, crucial for U.S. national security. It seeks to construct schema-based AI that overcomes the limitations of first-wave (rule-based, symbolic reasoning) and second-wave (machine learning) AI systems. KAIROS will create and apply schemas to identify, link, and sequence events in multimedia data, focusing on events that impact national security. The program involves two stages: learning schemas from big data and applying these schemas to multimedia/multilingual information to detect complex events of interest. A KAIROS Proposers Day was held in January 2019 in Arlington, VA. </details> |
| [2019](https://arxiv.org/abs/1911.02060) | KG-TE | Infusing Knowledge into the Textual Entailment Task Using Graph Convolutional Networks | [![Paper](https://img.shields.io/badge/Paper-arXiv'19-brightgreen)](https://arxiv.org/abs/1911.02060) | [![GitHub](https://img.shields.io/github/stars/IBM/knowledge-enabled-textual-entailment.svg?style=social)](https://github.com/IBM/knowledge-enabled-textual-entailment) | <details><summary>Summary</summary> The paper presents a KG-Augmented Entailment Model that infuses external knowledge from knowledge graphs into the textual entailment task using Graph Convolutional Networks. It introduces a method to generate contextual subgraphs from KGs, focusing on relevance and noise reduction. These subgraphs, encoded by GCNs, are combined with text-based models to enhance classification performance. The approach significantly improves entailment prediction accuracy, particularly on the challenging BreakingNLI dataset, demonstrating robustness and resilience. The model’s modularity allows compatibility with various text-based models and KGs, addressing challenges in effectively integrating external knowledge into NLI tasks and offering significant advancement over text-only models. </details> |
| [2019](https://arxiv.org/abs/1906.05317) | Comet | COMET: Commonsense Transformers for Automatic Knowledge Graph Construction | [![Paper](https://img.shields.io/badge/Paper-arXiv'19-brightgreen)](https://arxiv.org/abs/1906.05317) | [![GitHub](https://img.shields.io/github/stars/Unbabel/COMET.svg?style=social)](https://github.com/Unbabel/COMET) | <details><summary>Summary</summary>COMET introduces an innovative approach to expand commonsense knowledge graphs by integrating pre-trained language models with generative techniques. It focuses on constructing new knowledge by generating nodes and edges in existing graphs like ATOMIC and ConceptNet. COMET adapts deep contextualized models like BERT for generating rich, natural language descriptions of commonsense knowledge. It achieves remarkable precision, approaching human-level performance, thus offering a promising solution to the challenge of scaling high-precision commonsense knowledge bases. This method has significant implications for AI research, suggesting a shift towards generative methods for automatic knowledge base completion over traditional extractive approaches.</details> |
| [2018](https://arxiv.org/abs/1811.00146) | Atomic | ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning | [![Paper](https://img.shields.io/badge/Paper-arXiv'18-brightgreen)](https://arxiv.org/abs/1811.00146) | [![GitHub](https://img.shields.io/badge/Dataset-Hugging%20Face%20ATOMIC-blue)](https://huggingface.co/datasets/atomic) | <details><summary>Summary</summary>ATOMIC is a comprehensive atlas for machine commonsense reasoning, organized through 877,000 textual descriptions of inferential knowledge based on "if-then" relations. It introduces nine relation types, covering causes, effects, and stative aspects, related to events, mental states, and personas. Unlike traditional knowledge graphs that focus on taxonomic or encyclopedic knowledge, ATOMIC emphasizes inferential, event-based knowledge. The data, collected via crowdsourcing, contributes to an extensive coverage of everyday events. Training neural models on this dataset enhances their reasoning and inference abilities for unseen events. ATOMIC represents a significant step towards addressing the gap in commonsense reasoning in current AI systems.</details> |
| [2018](https://github.com/microsoft/jericho) | Jericho | A lightweight python-based interface connecting learning agents with interactive fiction games | N/A | [![GitHub](https://img.shields.io/github/stars/microsoft/jericho.svg?style=social)](https://github.com/microsoft/jericho) | <details><summary>Summary</summary> Jericho is a Python-based interface designed to connect learning agents with interactive fiction games, predominantly running on Linux and requiring Python 3, Spacy, and standard build tools like gcc. It streamlines the installation process either via PyPi or directly from GitHub. Key functionalities include a Frotz Environment, Object Tree, and Game Dictionary, enhancing the interaction with text-based games. Jericho facilitates actions and observations through string-based inputs in a reinforcement learning framework, supports game state saving and loading, and provides tools for accessing valid actions and game walkthroughs. Catering to diverse agent models like RCDQN, CALM, Q*BERT, and KG-A2C, Jericho stands as a versatile platform for research and development in text-based adventure games using reinforcement learning, encouraging community contributions while adhering to ethical open-source practices. </details> |
| [2018](https://api.semanticscholar.org/CorpusID:202558974) | ProPara | Everything Happens for a Reason: Discovering the Purpose of Actions in Procedural Text | [![Paper](https://img.shields.io/badge/Paper-SemanticScholar'18-blue)](https://api.semanticscholar.org/CorpusID:202558974) | [![AllenAI](https://img.shields.io/badge/AllenAI-ProPara-red)](https://allenai.org/data/propara) | <details><summary>Summary</summary> "Everything Happens for a Reason" introduces XPAD, a model designed to enhance the comprehension of procedural text, such as scientific processes or recipes, by not only predicting actions but also explaining their dependencies. The model extends the ProPara dataset with a focus on identifying why certain actions are necessary before others, based on the world state created by previous actions. XPAD significantly outperforms previous systems in explaining action dependencies and maintains performance on original tasks. The approach involves integrating background knowledge for more plausible effect predictions, potentially applicable to a wide range of texts involving procedural actions and state changes. </details> |
| [2017](https://www.nas.gov.ua/text/EuropeanIntegration/HR001117S0026%20(AIDA).pdf) | DARPA AIDA | Active Interpretation of Disparate Alternatives | [![Paper](https://img.shields.io/badge/Paper-DARPA'17-blue)](https://www.nas.gov.ua/text/EuropeanIntegration/HR001117S0026%20(AIDA).pdf) | [![DARPA](https://img.shields.io/badge/DARPA-AIDA-red)](https://www.darpa.mil/program/active-interpretation-of-disparate-alternatives) | <details><summary>Summary</summary> DARPA’s Active Interpretation of Disparate Alternatives (AIDA) program aims to develop a semantic engine to interpret complex events, situations, or trends from diverse, unstructured sources. Targeting revolutionary advancements in information interpretation, AIDA covers five technical areas: Semantic Mapping, Common Semantic Representation, Multiple Hypotheses, Integration, and Data. The program operates in three 18-month phases, emphasizing innovative research to create and aggregate structured information into a common semantic space. Managed through a scientific review process, AIDA evaluates proposals for their potential to offer substantial advancements, with the National Institute of Standards and Technology (NIST) handling program evaluations. AIDA offers multiple awards, including contracts and cooperative agreements, based on the quality of proposals. </details> |
| [2016](https://arxiv.org/abs/1612.03975) | ConceptNet (5.5) | An Open Multilingual Graph of General Knowledge | [![Paper](https://img.shields.io/badge/Paper-arXiv'16-brightgreen)](https://arxiv.org/abs/1612.03975) | [![GitHub](https://img.shields.io/github/stars/commonsense/conceptnet5.svg?style=social)](https://github.com/commonsense/conceptnet5/), [![ConceptNet](https://img.shields.io/badge/Website-ConceptNet-red)](https://conceptnet.io/) | <details><summary>Summary</summary> ConceptNet 5.5 is a versatile semantic graph that connects words and phrases in natural language through labelled edges, built from diverse sources like Wiktionary and OpenCyc. It represents terms in a standardized form and integrates knowledge from external databases. Significantly, ConceptNet is employed in enhancing word embeddings, merging distributional semantics from sources like word2vec with its semantic network to form the ConceptNet Numberbatch. This hybrid semantic space has shown excellent performance in word-relatedness evaluations and solving SAT-style analogies, demonstrating a high correlation with human judgment. The project's resources, including code and data, are publicly available on GitHub. </details> |
| [2014](https://dl.acm.org/doi/10.1145/2629489) | WikiData | A free collaborative knowledgebase | [![Paper](https://img.shields.io/badge/Paper-ACM'14-blue)](https://dl.acm.org/doi/10.1145/2629489) | [![GitHub](https://img.shields.io/github/stars/Wikidata.svg?style=social)](https://github.com/Wikidata) | <details><summary>Summary</summary> Wikidata serves as a multilingual knowledgebase, offering a unified source of structured data for Wikipedia and external applications. It allows public editing, leveraging a community-driven approach to manage and evolve its data schema. Using property-value pairs for structuring information, Wikidata encompasses diverse knowledge from primary sources, with ample reference details. It integrates with external databases, providing comprehensive data accessibility through web services in various formats. Its continuous evolution, driven by the community, fuels its application in numerous domains. All data in Wikidata is released under the Creative Commons CC0 license, ensuring free and widespread accessibility. </details> |
| [2012](https://en.wikipedia.org/wiki/Google_Knowledge_Graph) | Google KG | The Google Knowledge Graph | [![Website](https://img.shields.io/badge/Website-Wikipedia-red)](https://en.wikipedia.org/wiki/Google_Knowledge_Graph) | N/A | <details><summary>Summary</summary> The Google Knowledge Graph is a knowledge base integrated into Google's search engine. Launched in May 2012, it presents information in an infobox next to search results, offering instant answers. Initially focusing on entities like people, places, and businesses, the Knowledge Graph rapidly expanded, growing from 570 million entities in its first seven months to 70 billion facts by mid-2016, and 500 billion facts on 5 billion entities by May 2020. The graph sources information from various outlets, including Wikipedia and the CIA World Factbook, and also feeds into Google Assistant and Google Home voice queries. While enhancing Google searches, it has been criticized for lacking source citations and contributing to a decline in Wikipedia article readership. Moreover, it's been scrutinized for presenting biased or inaccurate information due to its automated information-gathering method. Despite these criticisms, the Knowledge Graph has become an integral part of Google's search infrastructure. </details> |
| [2010](https://coggle.it/diagram/Wlcm4xImdAABI9yH/t/watson-ibm-knowledge-base-prismatic) | PRISMATIC | Inducing knowledge from a large scale lexicalized relation resource | [![Paper](https://img.shields.io/badge/Paper-ACM'10-blue)](https://dl.acm.org/doi/10.5555/1866775.1866790) | N/A | <details><summary>Summary</summary> PRISMATIC, developed by IBM's Watson Research Lab, is an expansive lexicalized relation resource created from over 30 GB of text. It contains approximately 1 billion frames, each representing a semantic unit of relations in textual data. PRISMATIC is distinctive in its automatic creation and broad scope, focusing on detailed knowledge about predicates. The use of frame cuts allows for dissecting frames to induce knowledge patterns and make fine-grained type inferences. Its versatility lies in potential applications across various AI fields such as type inference, relation extraction, and textual entailment. PRISMATIC stands out for its automated approach to knowledge induction, offering substantial utility for future AI research. </details> |
| [2008](https://aclanthology.org/P08-1090/) | Chambers2008 | Unsupervised Learning of Narrative Event Chains | [![Paper](https://img.shields.io/badge/Paper-ACL'08-blue)](https://aclanthology.org/P08-1090/) | [![GitHub](https://img.shields.io/github/stars/narrative_chains/narrative_chains.svg?style=social)](https://github.com/kirubarajan/narrative_chains) | <details><summary>Summary</summary> Chambers and Jurafsky's paper introduces narrative event chains, a novel approach in NLP for extracting structured knowledge from texts. Unlike traditional hand-coded scripts, these chains are derived using unsupervised learning methods from raw text, focusing on events connected through a common protagonist. The process involves three steps: learning narrative relations between events, temporally ordering these events, and pruning them to form coherent narrative chains. The paper introduces the narrative cloze task as a new evaluation method for assessing event relatedness within these chains. A key innovation is the use of unsupervised distributional methods to establish narrative relations, emphasizing the role of protagonists in narrative coherence. The results demonstrate significant improvements over baseline methods in both narrative prediction and temporal coherence, indicating the potential of this approach in enhancing understanding of narrative structures in text. </details> |
| [2007](https://academic.oup.com/bioinformatics/article/23/14/1846/190290) | GeoQuery | A bridge between the Gene Expression Omnibus (GEO) and BioConductor | [![Paper](https://img.shields.io/badge/Paper-Bioinformatics'07-blue)](https://academic.oup.com/bioinformatics/article/23/14/1846/190290) | [![GitHub](https://img.shields.io/github/stars/seandavi/GEOquery.svg?style=social)](https://github.com/seandavi/GEOquery) | <details><summary>Summary</summary> GEOquery serves as a vital bridge between the Gene Expression Omnibus (GEO) and BioConductor, offering an efficient tool for accessing and analyzing a vast array of gene expression experiments. Designed to integrate with R's statistical programming environment, it automates the parsing of GEO's data formats, easing the analysis process. With the creation of custom data structures, GEOquery simplifies data retrieval through a single command, enhancing the utility for bioinformatics research. Its ability to convert GEO data into various BioConductor structures widens its application in genomics data analysis. As part of the Bioconductor project, GEOquery stands out for its user-friendly design and broad accessibility. </details> |
| [1975](https://www.ijcai.org/Proceedings/75/Papers/021.pdf) | Schank1975 | SCRIPTS, PLANS, AND KNOWLEDGE | [![Paper](https://img.shields.io/badge/Paper-ijcai--1975-blue)](https://www.ijcai.org/Proceedings/75/Papers/021.pdf) | N/A | <details><summary>Summary</summary> The paper by Schank and Abelson introduces 'scripts' as a theoretical framework in AI to understand common situations through predetermined, stereotypical sequences of actions. These scripts, composed of interlinked slots that influence each other, handle everyday scenarios and are distinct from 'plans' that deal with novel situations. The SAM program, which applies scripts for language understanding, demonstrates this concept. Plans, on the other hand, describe deliberate behavior and choices for achieving goals, crucial for making sense of language. The authors emphasize the role of 'forgetting' in effectively processing and remembering stories, suggesting that understanding involves filtering out unimportant details while retaining crucial information. This approach underlines the necessity of structured knowledge and 'forgetting heuristics' in AI for simulating human-like understanding and memory retention. </details> |


## Cognitive Architectures and Generative Models

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27710) | LLMs in ACT-R/Soar | Comparing LLMs for enhanced ACT-R and Soar Model Development. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27710) | N/A | <details><summary>Summary</summary>This study explores using ChatGPT4 and Google Bard to develop models for ACT-R and Soar in cognitive simulation. It involves two tasks: creating an ACT-R based driving simulation and using Soar to identify students' dominant intelligence types. The approach iteratively refines prompts to emulate cognitive actions and operations. The study documents challenges in integrating LLMs, offering solutions to improve model development. A significant contribution is the framework for prompt patterns, enhancing LLM interaction with cognitive architectures. The research highlights the potential of LLMs as interactive interfaces in cognitive modeling, paving the way for future explorations in the field.</details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27690) | LLMs for Cognitive Agents | Exploiting Language Models as knowledge sources for cognitive agents. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27690) | N/A | <details><summary>Summary</summary> The study explores integrating Large Language Models (LLMs) with cognitive architectures to provide cognitive agents with a rich source of task knowledge. It addresses the challenge of scaling cognitive agents to complex tasks, which hinges on their ability to acquire new knowledge. LLMs offer vast potential knowledge but face issues of reliability and trustworthiness. The paper suggests three integration patterns: indirect extraction, direct extraction, and direct knowledge encoding. Focusing on direct extraction, it outlines a method for agents to interact with LLMs to extract relevant task knowledge. This includes identifying knowledge gaps, formulating queries, interpreting responses, and verifying the extracted knowledge's applicability and accuracy. </details> |
| [2024](https://www.qrg.northwestern.edu/papers/Files/QRG_Dist_Files/QRG_2023/nakos_forbus_fss23_aaai_camera_ready.pdf) | LLM Cog Companion | Using Large Language Models in the Companion Cognitive Architecture: A Case Study and Future Prospects | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://www.qrg.northwestern.edu/papers/Files/QRG_Dist_Files/QRG_2023/nakos_forbus_fss23_aaai_camera_ready.pdf) | N/A | <details><summary>Summary</summary> The paper explores integrating large language models (LLMs) like BERT into the Companion cognitive architecture to enhance its natural language capabilities. The Companion architecture, which features a rule-based semantic parser CNLU, aims to create human-like software social organisms capable of learning, reasoning, and interacting through natural language. BERT is used for improving CNLU's disambiguation capabilities and augmenting knowledge extraction in reading tasks. The research also discusses using LLMs for low-resource disambiguation, simplifying text inputs for better processing, and directly generating predicate calculus from text. These integrations present unique challenges and opportunities, emphasizing the potential of combining LLMs with knowledge-rich cognitive architectures. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27683) | Chunks in Cognitive Arch | Method for generating knowledge chunks in cognitive architectures. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27683) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/w3c/cogai/blob/master/chunks-and-rules.md) | <details><summary>Summary</summary> This study presents a solution to the knowledge engineering bottleneck in cognitive architectures like ACT-R. It proposes using artificial intelligence methods, specifically natural language processing, to extract key entities, relationships, and attributes from unstructured text. These elements are then structured into triples or chunks, which can be used to augment the knowledge base of cognitive models. The primary application is in enhancing analogical reasoning within cognitive architectures. By automating the generation of knowledge chunks, this approach aims to reduce the time-intensive and expert-dependent process of knowledge engineering, enhancing the capabilities and efficiency of cognitive models in tasks like analogical reasoning. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27684) | Generative Models in CA | On Using Generative Models in a Cognitive Architecture for Embodied Agents. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27684) | N/A | <details><summary>Summary</summary> The paper discusses the integration of generative AI models, particularly Large Language Models like ChatGPT, into cognitive architectures, using the ICARUS framework as a reference point. It explores how generative models can enhance the capabilities of embodied agents in various cognitive tasks. The paper proposes using language as an intermediate medium for tasks beyond communication, including arithmetic, logical reasoning, and task planning. It highlights the potential use of these models in perception, inference, goal reasoning, and planning within the ICARUS architecture. Additionally, it addresses the challenge of LLMs' non-persistent learning by integrating them into a cognitive framework with long-term memory structures. </details> |
| [2024](https://arxiv.org/abs/2401.17464) | CoA-Reasoning | Efficient Tool Use with Chain-of-Abstraction Reasoning | [![Paper](https://img.shields.io/badge/Paper-arXiv'24-brightgreen)](https://arxiv.org/abs/2401.17464) | N/A | <details><summary>Summary</summary>  The paper introduces Chain-of-Abstraction Reasoning (CoA) as a method to enhance large language models (LLMs) for efficient multi-step reasoning. CoA involves fine-tuning LLMs to create reasoning chains with abstract placeholders, which are later filled with specific knowledge via domain tools. This method improves LLMs' reasoning robustness and reduces reliance on explicit domain knowledge, allowing for parallel decoding and tool usage. Tested on mathematical reasoning and Wikipedia QA tasks, CoA demonstrates superior QA accuracy and efficient tool usage compared to existing methods. Its versatility indicates potential applicability across various reasoning domains and LLM decoding strategies. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27686) | VSA | Bridging Cognitive Architectures and Generative Models with Vector Symbolic Algebras. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27686) | N/A | <details><summary>Summary</summary> The paper focuses on Vector Symbolic Algebras (VSAs) as a means to unify cognitive architectures with generative models. It presents VSAs as a comprehensive framework that can integrate symbolic and non-symbolic data, which is essential for cognitive models and neural networks. The paper explores the role of VSAs in creating kernel functions for data representation and views VSA-based memories as probabilistic distribution models. The study highlights the potential of VSAs in offering a unified approach to understanding cognition, brain activity, and uncertainty representations, but also acknowledges the challenges in resource management and the accuracy of high-dimensional vector representations. Future research directions include improving representation design and sampling techniques in VSAs. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27687) | ML & CS | Building Intelligent Systems by Combining Machine Learning and Automated Commonsense Reasoning. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27687) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/aravindvaddi/chatbot-concierge) | <details><summary>Summary</summary> The paper introduces a novel approach to building intelligent systems that closely emulate human cognitive processes by combining machine learning, particularly generative AI systems, for knowledge extraction from various sources, and automated commonsense reasoning. The extracted knowledge is translated into predefined predicates, and then reasoned over using the s(CASP) system, paralleling human's Kahneman's System 1 and System 2 thinking. This method has been applied to create systems for tasks like visual question answering, interactive chatbots, and autonomous driving, which not only respond interactively but also provide consistent, explainable outcomes. This approach ensures more reliable, human-like decision-making in AI systems, with applications demonstrated through a concierge bot example. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27689) | LLM & CA | Augmenting Cognitive Architectures with Large Language Models. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27689) | N/A | <details><summary>Summary</summary> This paper discusses augmenting cognitive architectures like Soar and Sigma with generative AI models, particularly Large Language Models (LLMs). It proposes integrating LLMs as a part of the cognitive architecture's declarative memory, which can be prompted to extract knowledge relevant to specific tasks. The integration approach leverages the strengths of both cognitive architectures and LLMs, aiming to create an agent that surpasses the capabilities of either approach used in isolation. The method involves using impasse-driven architecture to prompt LLMs and learn task-specific operator embeddings, thereby enhancing cognitive systems with the vast knowledge and processing abilities of LLMs. Future work includes evaluating this approach in interactive task learning and extending the Sigma architecture to incorporate these new functionalities. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27691) | LLM-CA | A Proposal for a Language Model Based Cognitive Architecture. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27691) | N/A | <details><summary>Summary</summary> Language Models (LLMs) by integrating them with cognitive architecture elements to address limitations in multi-step reasoning and compositionality. Drawing from dual-processing theory, the LMCA seeks to imbue LLMs with "slow thinking" abilities, characteristic of human cognitive effort and symbolic reasoning. Key components of LMCA include working memory with specialized buffers, a retrieval module, and distinct long-term memory modules for memory, thought, and action processing. Training LMCA presents challenges in data acquisition and necessitates mechanisms for continual learning and internal error generation. The proposal calls for software implementation and testing in real-world scenarios. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27692) | CA & Trans | Proposal for Cognitive Architecture and Transformer Integration. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27692) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/facebookresearch/gtn_applications) | <details><summary>Summary</summary> This proposal explores integrating Transformers with a cognitive architecture like Soar for real-time, online learning from an agent's experiences. Traditional Transformers, such as LLMs, are trained offline and lack essential cognitive agent capabilities, including decision-making and reasoning. The integration aims to enable the Transformer to learn from the agent’s experiences and predict future events, thoughts, or actions. Key challenges include adapting Transformers for online learning, ensuring learned knowledge is grounded in the agent's experiences, and maintaining real-time responsiveness. Successful integration could endow agents with enhanced cognitive abilities like anomaly detection, action and world modeling, and anticipatory capabilities for complex environments. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27693) | Minds&Mach | Combining Minds and Machines: Fusion of Cognitive Architectures and Generative Models. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27693) | N/A | <details><summary>Summary</summary> This paper investigates the fusion of cognitive architectures (CAs) and generative models to create general embodied intelligence. CAs, focusing on human-like cognitive processes, provide structured decision-making frameworks, whereas generative models excel in creative content generation. Despite their strengths, CAs face challenges in modeling complex cognitive phenomena, and generative models often struggle with coherence and contextual relevance. The integration of these approaches aims to leverage the interpretability and reasoning of CAs with the creative capabilities of generative models, enhancing the overall capabilities of intelligent agents. The paper explores various integration strategies, including hybrid models, and provides a case study in a nuclear power plant, demonstrating enhanced cognitive robots and digital humans. </details> |
[2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27694) | EmbodGen | Growing an Embodied Generative Cognitive Agent. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27694) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/charles-river-analytics/Scruff.jl) | <details><summary>Summary</summary> This paper presents an approach to developing an embodied generative cognitive agent by integrating large language models (LLMs) with embodied cognitive architectures. Drawing from an evolutionary perspective, it posits that all goals, including those of cognitive agents, are fundamentally physiological. The proposed model emphasizes that object properties and categories are not intrinsic but constructed in relation to an agent’s goals. The paper argues that current LLMs, while generative at a behavioral level, require deeper cognitive integration. It suggests a model where perception and concept formation are goal-driven, advocating for a predictive coding approach across different levels of cognition in the agent’s architecture. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27695) | The Grounding Problem | The Grounding Problem: Integration of Cognitive and Generative Models. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27695) | N/A | <details><summary>Summary</summary> This paper discusses the integration of cognitive and neural AI paradigms, focusing on the grounding problem as the key challenge. Grounding involves how AI systems develop meaningful semantics from representations without direct interaction with the world. The paper identifies five types of grounding (sensorimotor, communicative, epistemic, relational, and referential) essential for AI systems. By addressing the grounding problem, the authors propose that integrating cognitive models with connectionist approaches can overcome limitations of current AI systems. This integration, which encompasses social and ethical dimensions, is exemplified in computational creativity and educational applications. The approach highlights the importance of aligning AI systems with human values and societal expectations. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27696) | GenInstLearn | Generative Environment-Representation Instance-Based Learning: A Cognitive Model. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27696) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/mighty-gerbils/gerbil) | <details><summary>Summary</summary>The Generative Environment-Representation Instance-Based Learning (GERIBL) model integrates generative models (GMs) with Instance-Based Learning Theory (IBLT) to enhance learning in dynamic decision-making tasks. GERIBL uses Artificial Neural Networks, specifically generative models like AutoEncoders and Generative Adversarial Networks, to automatically generate representations of complex tasks. This integration provides a new approach to forming task-relevant environment features and similarity metrics. The model was evaluated through experiments on visual utility learning and transfer of learning, demonstrating its ability to emulate human-like performance. Smaller representation sizes in GMs generally yielded better results, highlighting the model's potential in cognitive architecture and decision-making research.</details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27697) | LLM-IBL | Exploring Instructions to Rewards with LLMs in Instance-Based Learning. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27697) | N/A | <details><summary>Summary</summary> This study proposes using Large Language Models (LLMs) to enhance instance-based learning by incorporating descriptive information into experiential learning. The approach involves prompting LLMs with task instructions to define critical actions and assign values to these actions for successful task completion. In an initial experiment involving a grid-world task, this method significantly improved the learning of a cognitive model. The study addresses the challenge of temporal credit assignment by using LLM-interpreted instructions to provide dense reward signals, guiding the learning process. This approach demonstrates the potential of LLMs to enrich cognitive models with descriptive information, facilitating more efficient and effective learning. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27698) | Psycho-Gen-Agents | Psychologically-Valid Generative Agents in Agent-Based Modeling. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27698) | N/A | <details><summary>Summary</summary> The paper introduces Psychologically-Valid Generative Agents (PVGAs), a new framework for agent-based modelling in social sciences. It combines cognitive architectures, large language models (LLMs), and stance detection to simulate realistic human behaviours. This approach enables agents to make data-driven, cognitively-constrained decisions and generate human-like linguistic data. The framework builds on prior work with Psychologically Valid Agents (PVAs) within the ACT-R architecture, particularly in modelling human behaviour during the COVID-19 pandemic. By integrating agent-based modelling with generative AI and stance detection, PVGAs offer a robust method for understanding complex social phenomena and individual behaviours, enhancing research in public health, social sciences, and other domains. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27699) | CG-AI | Cognitive Architecture for Common Ground Sharing in Model-Model Interaction. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27699) | N/A | <details><summary>Summary</summary> This study focuses on developing a model to understand and improve common grounding between humans and generative AIs. It utilizes the Tangram Naming Task (TNT) as a testbed for examining the process of building a common cognitive framework essential for effective communication. The methodology includes generative AI models that simulate the internal processes of communication, where one model generates descriptions of abstract figures and another interprets these descriptions. Preliminary results show task performance exceeding chance levels, suggesting the successful implementation of a common cognitive framework. The study aims to refine these models further, paving the way for enhanced human-AI interaction and communication in the future. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27701) | Neuro-Cog | High-Level Machine Reasoning with Cognitive Neuro-Symbolic Systems. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27701) | N/A | <details><summary>Summary</summary> This paper proposes a method to enhance AI systems' reasoning capabilities by integrating cognitive architectures with neuro-symbolic components, focusing on high-level reasoning akin to human common sense. Addressing the limitations in large language models (LLMs) and autonomous systems, the authors suggest a hybrid framework centered on the ACT-R cognitive architecture. This integration aims to bring structured knowledge and advanced reasoning to AI systems. The paper also discusses the evolving role of generative AI in cognitive systems and suggests future directions, including scaling cognitive models using LLMs and improving LLMs through cognitive model-based prompt engineering, offering a path toward more sophisticated AI reasoning capabilities. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27703) | Auto-Know | Automating Knowledge Acquisition with LLMs for Cognitive Agents. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27703) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/uwnlp/nlp-corpora/tree/master/doc/byu-coca) | <details><summary>Summary</summary> This paper describes an experiment using large language models (LLMs) to automate the learning of new entries in a cognitive agent's semantic lexicon. The approach is part of content-centric computational cognitive modeling, which relies heavily on extensive knowledge resources. The experiment aims to expand the semantic lexicon by learning expressions equivalent to transitive verbs. It employs a five-step process utilizing LLMs, including generating synonymous multiword expressions (MWEs). An innovative prompting architecture and a chain-of-thought approach guide the LLMs to produce relevant outputs. The experiment's success demonstrates the potential for integrating LLMs in automated knowledge acquisition for cognitive agents. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27704) | SecurSoar | Proposed Uses of Generative AI in a Cybersecurity-Focused Soar Agent. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27704) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/aica-iwg/aica-agent/) | <details><summary>Summary</summary>Argonne National Laboratory's project on autonomous intelligent cybersecurity agents (AICAs) aims to counter advanced cybersecurity threats using cognitive architecture, specifically Soar. The project addresses the rising use of AI in cybersecurity, both defensively and maliciously. However, the current use of Soar is limited in handling novel situations due to a lack of modern AI principles for dynamic analysis. The proposed solution involves integrating generative AI with Soar to enhance its capabilities in contextual understanding and learning. The architecture focuses on protecting critical infrastructures and employs a centralized system for threat sharing and decision-making, leveraging both symbolic and generative AI to process diverse cybersecurity data efficiently.</details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27705) | LeverageConf | Leveraging Conflict to Bridge Cognitive Reasoning and Generative Algorithms. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27705) | N/A | <details><summary>Summary</summary> This position paper proposes a novel framework to address the challenges autonomous agents face in non-stationary environments. It integrates cognitive reasoning with generative algorithms, leveraging metacognitive conflict resolution to adapt to unexpected dynamics. The framework builds on the Common Model of Cognition, focusing on conflict detection as a trigger for agents to refine their cognitive strategies and update policies. It incorporates metalevel control, addressing resource constraints and utilizing generative models for prediction and perception. The aim is to seamlessly bridge low-level perceptual processes with higher-order cognitive functions, enabling agents to operate effectively in dynamic and unpredictable environments. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27706) | Synerg-LLM | Integrating LLMs and Cognitive Architectures for Robust AI. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27706) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/Significant-Gravitas/Auto-GPT) | <details><summary>Summary</summary> This paper investigates the synergistic integration of Large Language Models (LLMs) and Cognitive Architectures (CAs) to enhance robust AI systems. It presents three distinct integration approaches: Modular, Agency, and Neuro-Symbolic. The Modular approach varies the degree of integration, using augmented LLMs and chain-of-thought prompting. The Agency approach, influenced by Society of Mind theory, involves micro and macro levels of cognitive interaction, while the Neuro-Symbolic approach, inspired by the CLARION architecture, combines bottom-up and top-down learning. This exploration aims to harness the complementary strengths of LLMs and CAs, addressing each field's limitations to advance AI development. </details> |
| [2023](https://arxiv.org/abs/2309.02427) | CoALA | Cognitive Architectures for Language Agents | [![Paper](https://img.shields.io/badge/Paper-arXiv'23-brightgreen)](https://arxiv.org/abs/2309.02427) | [![GitHub](https://img.shields.io/github/stars/ysymyth/awesome-language-agents.svg?style=social)](https://github.com/ysymyth/awesome-language-agents) | <details><summary>Summary</summary> The paper discusses the integration of large language models (LLMs) and production systems in developing language agents, proposing the Cognitive Architectures for Language Agents (CoALA) framework. CoALA organizes language agents with modular memory components, structured action spaces, and decision-making processes, drawing inspiration from the historical evolution of cognitive science and artificial intelligence. The framework views LLMs as probabilistic production systems, using prompt engineering as a control mechanism. It aims to provide a structured approach to creating more sophisticated language agents capable of reasoning, planning, and memory management. This approach seeks to bridge traditional AI methodologies with modern generative models, paving the way for language-based general intelligence. </details> |
| [2023](https://arxiv.org/abs/2308.09830) | Symbolic LLM's | Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis | [![Paper](https://img.shields.io/badge/Paper-arXiv'23-brightgreen)](https://arxiv.org/abs/2308.09830) | N/A | <details><summary>Summary</summary> This paper explores the integration of Large Language Models (LLMs) and Cognitive Architectures (CAs) for developing more robust AI systems. It presents three integration approaches: Modular, Agency, and Neuro-Symbolic. The Modular approach varies integration degrees, employing chain-of-thought prompting and augmented LLMs. The Agency approach, inspired by the Society of Mind theory, involves interactions of agents at micro and macro levels. The Neuro-Symbolic approach, based on the CLARION architecture, combines bottom-up and top-down learning processes. These integrations aim to leverage the strengths of both LLMs and CAs while mitigating their individual limitations, proposing novel architectures for AI advancement.</details> |
| [2022](https://arxiv.org/abs/2201.09305) | ACT-R VS Soar | An Analysis and Comparison of ACT-R and Soar | [![Paper](https://img.shields.io/badge/Paper-arXiv'22-brightgreen)](https://arxiv.org/abs/2201.09305) | N/A | <details><summary>Summary</summary> This paper provides a detailed analysis and comparison of two cognitive architectures: ACT-R and Soar. It delves into their overall structures, representations of agent data and metadata, and associated processing, focusing on working memory, procedural memory, and long-term declarative memory. The paper highlights the commonalities and differences between these two architectures, which are shaped by their primary goals: cognitive modeling for ACT-R and development of general AI agents for Soar. It identifies the processes and distinct classes of information used by these architectures, exploring the roles of metadata in decision making, memory retrievals, and learning. The analysis contributes to a deeper understanding of these cognitive models and their potential applications. </details> |
| [2022](https://soargroup.github.io/rosie/) | ROSIE (from SOAR) | Rosie (RObotic Soar Instructable Entity) is an agent written in the Soar Cognitive Architecture | [![Website](https://img.shields.io/badge/Website-See_Details-blue)](https://soar.eecs.umich.edu/) | [![GitHub](https://img.shields.io/github/stars/SoarGroup/rosie.svg?style=social)](https://github.com/SoarGroup/rosie) |  <details><summary>Summary</summary> Rosie, the Robotic Soar Instructable Entity, is a project at the University of Michigan Soar Lab. It's an agent written in the Soar Cognitive Architecture that learns tasks through situated interactive instruction, showcasing capabilities in the area of Interactive Task Learning (ITL). Rosie stands out for its ability to learn entirely new tasks and concepts from just one example and apply this knowledge in varied scenarios. This agent, led by Professor John E. Laird and a team, can detect gaps in its knowledge and actively seek information or initiate interactions to fill these gaps. Rosie has been employed to learn games, puzzles, household tasks, and more, demonstrating its adaptability in real-time and interactive learning environments. </details> |
| [2018-22](https://soar.eecs.umich.edu/) | SOAR | Soar Cognitive Architecture | [![Website](https://img.shields.io/badge/Website-See_Details-blue)](https://soar.eecs.umich.edu/) | [![GitHub](https://img.shields.io/github/stars/SoarGroup/Soar.svg?style=social)](https://github.com/SoarGroup/Soar) | <details><summary>Summary</summary>Soar 9.6.2, the latest version of a cognitive architecture for intelligent behavior development, is now available for download. It includes enhancements to the debugger, CLI, and VisualSoar, along with bug fixes. The 43rd Soar Workshop will be hosted by the University of Michigan in 2023, featuring beginner and advanced tutorials. Recent achievements include Mininger and Laird winning Best Demonstration at the 2022 AAAI Conference. VISCA-2021 was hosted by the same group, focusing on various aspects of cognitive architecture. Significant contributors, Laird and Rosenbloom, received the 2018 Herbert A. Simon Prize for their work on Soar. The Soar platform is also utilized in unique installations like LuminAI and autonomous underwater vehicle IVER. Recent publications highlight Soar's diverse applications in AI and cognitive science. Soar, evolving since 1983, aims to address a wide range of intelligent agent tasks and incorporates multiple forms of knowledge and problem-solving methods. It seeks to approximate complete rationality by combining relevant knowledge for decision-making and is moving towards multiple learning mechanisms and representations of long-term knowledge for better functionality and performance. </details> |
| [1989](https://www.sciencedirect.com/science/article/abs/pii/0004370289900775) | Structure Mapping Engine | A computational model for analogical reasoning based on psychological theory. | [![Paper](https://img.shields.io/badge/Paper-ScienceDirect'89-blue)](https://www.sciencedirect.com/science/article/abs/pii/0004370289900775) | N/A | <details><summary>Summary</summary>Overview of SME's role in problem-solving and concept comprehension through analogy. The Structure-Mapping Engine (SME) is a program that facilitates the study of analogical processing, based on the structure-mapping theory of analogy. It is designed to be flexible and efficient, making it useful in both cognitive simulation studies and machine learning. SME operates by constructing consistent interpretations of potential analogies, following a three-stage process that includes access, mapping and inference, and evaluation. The program adheres to constraints of structural consistency and one-to-one mapping, supported by empirical psychological evidence. SME's algorithm involves several steps, including match construction and evaluation, and has been applied in various domains including psychological studies and concept learning.</details> |

## Common Model of Cognition

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27707) | Gen-CMC | Opportunities and Challenges in Applying Generative Methods to Exploring and Validating the Common Model of cognition. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27707) | N/A | <details><summary>Summary</summary> This paper focuses on applying generative methods like Dynamic Causal Modeling (DCM) to explore and validate the Common Model of Cognition (CMC). As CMC expands, its complexity increases, presenting challenges in validating and comparing intricate network structures. Alternative methods such as regression DCM (rDCM) and Biophysical Network Modeling (BNM) are considered for handling these complexities. However, a significant challenge remains in reliably comparing models of varying complexities. Tools like sparse rDCM may assist in identifying plausible connections within complex networks, but there's still a need to develop robust comparison methods to evaluate and validate these expanded cognitive models effectively. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27702) | COG-GEN | Neuro-Mimetic Realization of the Common Model of Cognition via Hebbian Learning and Free Energy Minimization. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27702) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/NACLab/ngc-learn) | <details><summary>Summary</summary>Introduces COGnitive Neural GENerative system for representing the Common Model of Cognition using Hebbian learning and free energy principle. CogNGen is a pioneering cognitive architecture that integrates the Common Model of Cognition with contemporary neural generative models. It employs neurobiologically plausible elements, such as neural generative coding and vector-symbolic memory models, adhering to predictive processing principles. The architecture optimizes a variational free energy functional, balancing model complexity and accuracy. It features sophisticated memory systems, including working and long-term memory modeled on MINERVA 2 and Hopfield networks. CogNGen's effectiveness in complex maze-solving tasks demonstrates its potential. Future enhancements aim to scale up the architecture for more challenging tasks, refine memory systems, and advance perceptual and motor modules. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27708) | Cog-FM | Integrating Cognitive Architectures with Foundation Models. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27708) | N/A | <details><summary>Summary</summary>Discusses integrating cognitive architectures with foundation models for few-shot learning. The paper proposes an integration of cognitive architectures and foundation models to support trusted artificial intelligence. It aims to use cognitive architectures for their strengths in human-like few-shot learning and managing the vast data processed by foundation models, which often suffer from inaccuracies and hallucinations. Trust in AI is a central focus, emphasizing the difference between AI trustworthiness and human trust. The potential synergy between these systems could be realized by using foundation models as knowledge repositories for cognitive architectures, thereby addressing scalability and memory issues. Future research is directed towards developing neuro-symbolic AI and context-aware models for more reliable and trustworthy AI applications. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27709) | BridgeGen | Bridging Generative Networks with the Common Model of Cognition. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27709) | N/A | <details><summary>Summary</summary>Presents a framework for adapting the CMC to large generative network models in AI. This article presents a theoretical framework for adapting the Common Model of Cognition (CMC) to large generative network models within AI. It suggests restructuring CMC modules into shadow production systems that are peripheral to a central production system, which handles higher-level reasoning based on the output of shadow productions. This integration of symbolic reasoning and connectionist statistical learning aims to enhance CMC models with advanced cognitive abilities. The proposed reformulation, particularly of the ACT-R module conception, involves incorporating generative pre-trained networks. Central elements like procedural memory and working memory are maintained, while chunks and buffers facilitate communication and data processing within the architecture. </details> |

## Memory AI major projects

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2022](https://openreview.net/forum?id=ZVBtN6B_6i7) | Learn2Expire | Learning to Expire: Synthesizing Lifelike Influence Expiry Times for Transformer Recommendations | [![arXiv](https://img.shields.io/badge/arXiv-2022-brightgreen)](https://openreview.net/forum?id=ZVBtN6B_6i7) | [![GitHub](https://img.shields.io/github/stars/lucidrains/learning-to-expire-pytorch.svg?style=social)](https://github.com/lucidrains/learning-to-expire-pytorch) | <details><summary>Summary</summary> The paper introduces Expire-Span, a novel approach for efficient long-term memory management in sequence modelling. By assigning an expiration value to each memory state, the model selectively retains important information while expiring irrelevant data. This method is integrated into Transformer architectures, significantly enhancing their capacity to handle longer memory spans. Experimental results demonstrate its effectiveness in various tasks, including natural language processing and reinforcement learning. Expire-Span achieves state-of-the-art results, efficiently processing memory sizes up to tens of thousands. Its scalability and efficiency offer significant potential for complex applications requiring extensive and dynamic memory management. </details> |
| [2024](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27688) | LLM-Memory | Memory Matters: The Need to Improve Long-Term Memory in LLM-Agents. | [![Paper](https://img.shields.io/badge/Paper-AAAI'24-blue)](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27688) | [![GitHub](https://img.shields.io/github/stars/.svg?style=social)](https://github.com/jina-ai/dev-gpt279) | <details><summary>Summary</summary>Reviews current efforts in developing LLM agents with a focus on improving long-term memory using vector databases. Highlights challenges and proposes future research topics. The paper reviews the development of autonomous agents using large language models (LLMs) and focuses on enhancing their long-term memory. It discusses how vector databases are pivotal for storing and retrieving long-term memory in LLM agents. The paper identifies challenges in memory management, such as differentiating types of memories and managing lifelong memories. Future research areas include improving metadata use in memory and integrating external knowledge sources. The document also highlights existing LLM agents like Auto-GPT and Voyager, detailing their functionalities and limitations. Finally, it proposes aligning LLM agents with cognitive architectures to effectively manage procedural, semantic, and episodic memories.</details> |


## Meta-level control major projects

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2023](https://groundhog-shallot-pen6.squarespace.com/explicable-insights) | CORA | Elemental AI Cognition product | N/A | [![Website](https://img.shields.io/badge/Website-CORA-red)](https://groundhog-shallot-pen6.squarespace.com/explicable-insights) | <details><summary>Summary</summary>Cora enables researchers to rapidly explore open-ended, complex questions and discover insights and answers grounded in factual, trustworthy, and contextualized evidence. Cora’s AI guides researchers to discover plausible answers that connect evidence across, and not just within, sources. </details> |
| [2023](https://direct.mit.edu/pages/cognet) | MIT COGENT | Elemental AI Cognition product | [![Conference](https://img.shields.io/badge/Conference-MITECS-blue)](https://direct.mit.edu/books/edited-volume/5452/The-MIT-Encyclopedia-of-the-Cognitive-Sciences) | [![Website](https://img.shields.io/badge/Website-MIT_CogNet-red)](https://direct.mit.edu/pages/cognet) | <details><summary>Summary</summary> The MIT Encyclopedia of the Cognitive Sciences (MITECS), edited by Robert A. Wilson and Frank C. Keil and published by The MIT Press, is a comprehensive reference work encapsulating the diversity of methodologies and theories in the cognitive sciences. Since the 1970s, cognitive sciences have evolved multidisciplinarily, shaping our understanding of the mind and cognition. MITECS offers 471 concise entries on key concepts from Acquisition to Wundt and X-bar Theory, each written by a leading researcher. It includes six extended essays overviewing major areas of cognitive science: Philosophy, Psychology, Neurosciences, Computational Intelligence, Linguistics and Language, and Culture, Cognition, and Evolution. This encyclopedia, valuable for students and researchers, serves as a guide to the current state of cognitive sciences, with each article providing accessible introductions and references for further reading. </details> |
| [2022](https://arxiv.org/abs/2011.13354) | BRAID | Weaving Symbolic and Neural Knowledge into Coherent Logical Explanations | [![Paper](https://img.shields.io/badge/Paper-ArXiv'22-brightgreen)](https://arxiv.org/abs/2011.13354) | [![GitHub](https://img.shields.io/github/stars/ec-ai/braid.svg?style=social)](https://ec.ai/) | <details><summary>Summary</summary> Braid is a novel logical reasoner that blends symbolic reasoning with statistical methods, addressing limitations of traditional symbolic engines like brittle inference and knowledge gaps. It introduces custom unifiers and dynamic rule generation to allow flexible term matching and hypothesize rules from a knowledge base. Braid's distributed, task-based framework efficiently constructs proof graphs, making it scalable. The reasoner demonstrates its efficacy in commonsense reasoning tasks like the ROC Story Cloze Test, achieving near state-of-the-art results with logical explanations. It incorporates frame-based approaches and integrates neural models for rule generation, showing adaptability and effectiveness in improving reasoning with user feedback.  </details> |
| [2022](https://arxiv.org/abs/2205.07830) | FactPEGASUS | Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization | [![Paper](https://img.shields.io/badge/Paper-ArXiv'22-brightgreen)](https://arxiv.org/abs/2205.07830) | [![GitHub](https://img.shields.io/github/stars/meetdavidwan/factpegasus.svg?style=social)](https://github.com/meetdavidwan/factpegasus) | <details><summary>Summary</summary> The document proposes a multimodal anomaly detection system for IoT security, leveraging transformer-based models to handle diverse data types effectively. It integrates information from different modalities using a fusion module and employs pre-training and fine-tuning for adaptation to specific IoT datasets. Experimental results demonstrate its effectiveness in detecting anomalies across various IoT data streams, surpassing baseline methods. The approach shows promise for enhancing security in real-world IoT applications like smart homes and industrial IoT. Future research directions include exploring advanced transformer architectures and addressing scalability and deployment challenges in IoT environments. </details> |
| [2022](https://arxiv.org/abs/2204.06508) | FactGraph | FactGraph: Evaluating Factuality in Summarization with Semantic Graph Representations | [![Paper](https://img.shields.io/badge/Paper-ArXiv'22-brightgreen)](https://arxiv.org/abs/2204.06508) | [![GitHub](https://img.shields.io/github/stars/amazon-science/fact-graph.svg?style=social)](https://github.com/amazon-science/fact-graph) | <details><summary>Summary</summary> Factuality evaluation in summarization is crucial but challenging due to existing models' lack of consistency with source documents. FACTGRAPH addresses this by decomposing documents and summaries into structured meaning representations (MR) using semantic graphs. It employs a graph encoder augmented with structure-aware adapters to capture semantic relations comprehensively. By combining text and graph representations, FACTGRAPH achieves superior performance, outperforming previous methods by up to 15% in factuality assessment. It excels in detecting content verifiability errors and identifying subsentence-level factual inconsistencies, offering a promising avenue for enhancing summarization quality in real-world applications. </details> |
| [2022](https://arxiv.org/abs/2210.01240) | PrOntoQa | A Systematic Formal Analysis of Chain-of-Thought | [![Paper](https://img.shields.io/badge/Paper-ArXiv'22-brightgreen)](https://arxiv.org/abs/2210.01240) | [![GitHub](https://img.shields.io/github/stars/asaparov/prontoqa.svg?style=social)](https://github.com/asaparov/prontoqa) | <details><summary>Summary</summary> existing benchmarks don't directly assess their reasoning process. To address this, PRONTOQA, a new dataset, is introduced, enabling systematic exploration of language models' reasoning abilities. Analysis on models like INSTRUCTGPT and GPT-3 reveals proficiency in individual deduction steps but struggles with proof planning when faced with multiple valid options. PRONTOQA facilitates easy analysis by converting CoT into symbolic proofs, allowing direct evaluation of reasoning. Results suggest pretraining significantly influences LLM reasoning, especially in fictional contexts. PRONTOQA aids in understanding LLMs' capabilities and limitations, crucial for future research and model development. </details> |
| [2021](https://arxiv.org/abs/2110.01834) | SOFAI | Thinking Fast and Slow in AI: the Role of Metacognition | [![Paper](https://img.shields.io/badge/Paper-ArXiv'21-brightgreen)](https://arxiv.org/abs/2110.01834) | [![Website](https://img.shields.io/badge/Website-SOFAI-red)](https://sites.google.com/view/sofai/home) | <details><summary>Summary</summary> Advancements in AI remain predominantly in narrow domains, lacking the adaptability and generalizability of human intelligence. Integrating insights from Kahneman's "Thinking, Fast and Slow," the SOFAI architecture blends fast (system 1) and slow (system 2) agents, mimicking human cognitive processes. A meta-cognitive agent arbitrates between these systems, assessing resource constraints, solver abilities, and past experiences to optimize decision-making. Employing a two-phase assessment process inspired by human introspection, SOFAI balances speed and accuracy. By default, it employs system 1 solvers, akin to human intuition, minimizing time-to-action. SOFAI instances are being tested in various real-life sequential decision scenarios to enhance AI performance and flexibility. </details> |
| [2021](https://arxiv.org/abs/2010.10597) | SKATE | A Natural Language Interface for Encoding Structured Knowledge | [![Paper](https://img.shields.io/badge/Paper-ArXiv'21-brightgreen)](https://arxiv.org/abs/2010.10597) | [![Website](https://img.shields.io/badge/Website-SKATE-red)](https://ec.ai/) | <details><summary>Summary</summary> SKATE, a natural language interface, minimizes the disparity between user input and system comprehension by iteratively refining natural language through semi-structured templates. Leveraging a neural semantic parser, suggests templates filled recursively for fully structured interpretations. Integrated with a neural rule-generation model, it facilitates the interactive acquisition of commonsense knowledge. Initial assessments demonstrate SKATE's effectiveness in comprehending stories. The architecture entails concept recognition, interpreted template production, and user refinement. Utilizing semantic frames processed by downstream applications, SKATE comprises components such as target representation vocabulary, concept recognizer, and semantic converter. Its applications span story understanding tasks to specialized domains like COVID-19 policy design, showcasing versatility and adaptability. </details> |
| [2020](https://arxiv.org/abs/2009.07758) | GLUCOSE | GeneraLized and COntextualized Story Explanations | [![Paper](https://img.shields.io/badge/Paper-ArXiv'20-brightgreen)](https://arxiv.org/abs/2009.07758) | [![Website](https://img.shields.io/badge/Website-GLUCOSE-red)](https://ec.ai/) | <details><summary>Summary</summary> GLUCOSE introduces a dataset capturing implicit commonsense causal knowledge within narrative contexts. It encompasses ten dimensions of causal explanation, addressing events, states, motivations, emotions, and naive psychology. Specific causal statements paired with general inference rules facilitate AI understanding. Utilizing a crowdsourcing platform, over 670K annotations were gathered from lay workers, focusing on everyday children's stories. The dataset tackles the challenge of acquiring and integrating commonsense knowledge into AI systems. GLUCOSE explanations adopt semi-structured inference rules, balancing between free text and logical forms, promoting better generalization. By scaffolding cognitive development in AI systems, GLUCOSE aims to enhance causal reasoning and generalization capabilities. The dataset and models are released for the AI research community to advance commonsense reasoning in various applications. </details> |



## Benchmarks 

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2023](https://arxiv.org/abs/2210.12678) | ComFact | A Benchmark for Linking Contextual Commonsense Knowledge | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2210.12678) | [![GitHub](https://img.shields.io/github/stars/Silin159/ComFact.svg?style=social)](https://github.com/Silin159/ComFact) | <details><summary>Summary</summary> The paper introduces ComFact, a benchmark for commonsense fact linking, addressing the challenge of retrieving relevant knowledge from KGs for NLP systems. It highlights significant performance gains (34.6% F1) over heuristic methods, emphasizing the importance of accurate fact retrieval. Downstream tasks like dialogue response generation benefit from improved knowledge retrieval (9.8% average improvement). However, models still fall short of human performance, indicating research opportunities in commonsense augmentation. Challenges such as contextual relevance and implicitness are identified, prompting the need for more sophisticated retrieval methods. The proposed task and benchmark aim to foster advancements in commonsense fact linking, setting the stage for future research in NLP. </details> |
| [2023](https://arxiv.org/abs/2310.15239) | Crow | Benchmarking Commonsense Reasoning in Real-World Tasks | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2310.15239) | [![GitHub](https://img.shields.io/github/stars/mismayil/crow.svg?style=social)](https://github.com/mismayil/crow) | <details><summary>Summary</summary> The CROW benchmark innovatively evaluates commonsense reasoning in real-world tasks for NLP systems. Contrasting with artificial scenarios in existing datasets, CROW embeds commonsense-violating perturbations into six real-world tasks, including machine translation, open-domain dialogue, and safety detection. It employs a multi-stage data collection pipeline to rewrite examples from existing datasets, challenging models with nuanced reasoning tasks. The benchmark uses Macro-F1 and Situational Accuracy for evaluation, uncovering a significant gap between human performance and current NLP models. While CROW marks a significant advancement in commonsense reasoning benchmarks, it also acknowledges limitations like a narrow focus on commonsense dimensions and potential crowdsourcing biases. </details> |
| [2023](https://arxiv.org/abs/2209.06293)  | CaptionCon | Do Androids Laugh at Electric Sheep? -  Humor "Understanding" Benchmarks from The New Yorker Caption Contest. A corpus for caption generation models | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2209.06293) | [![GitHub](https://img.shields.io/github/stars/jmhessel/caption_contest_corpus.svg?style=social)](https://github.com/jmhessel/caption_contest_corpus) | <details><summary>Summary</summary>  </details> |
| [2022](https://ceur-ws.org/Vol-3342/paper-8.pdf) | Causal Relation Benchmark | Knowledge Graph Embeddings for Causal Relation Prediction | [![Paper](https://img.shields.io/badge/Conference-CEUR_WS-blue)](https://ceur-ws.org/Vol-3342/paper-8.pdf) | [![Zenodo](https://img.shields.io/github/stars/your-github-username/your-repository.svg?style=social)](https://zenodo.org/records/7195904) | <details><summary>Summary</summary> This research investigates if AI models can grasp humor by using tasks based on the New Yorker Cartoon Caption Contest, which require understanding the sophisticated interplay between cartoon images, captions, and cultural allusions. The tasks involve matching jokes to cartoons, identifying winning captions, and explaining the humor. Despite employing advanced models like GPT-4, AI performance lagged behind humans, exposing a significant gap in AI's humor comprehension. The study utilizes a comprehensive dataset from 14 years of contests and includes rich human-authored annotations. The findings and resources are made public, contributing to future AI research in humor understanding. However, the research's focus on New Yorker humor might limit its applicability to broader humor types. </details> |
| [2022](https://arxiv.org/abs/2309.12423) | Wikidata Causal Event Triple Data | Event Prediction using Case-Based Reasoning over Knowledge Graphs | [![arXiv](https://img.shields.io/badge/arXiv-2022-brightgreen)](https://arxiv.org/abs/2309.12423) | [![Zenodo](https://img.shields.io/github/stars/your-github-username/your-repository.svg?style=social)](https://zenodo.org/records/7196049) | <details><summary>Summary</summary> The research investigates the effectiveness of Knowledge Graph (KG) embeddings in predicting causal relations between news events, a task hindered by the sparsity of existing causal KGs like Wikidata. By evaluating five different KG embedding and GCN-based link prediction methods, the study seeks to understand their capabilities in causal relation prediction. Two new causal KG datasets, WikiCV and WikiMV, were created from Wikidata for this purpose. The evaluation included classical accuracy measures and a novel manual approach, revealing that no single method consistently outperformed others. The study concludes that while current methods show limitations, they offer valuable contributions, indicating potential areas for future advancements in causal relation prediction. </details> |
| [2022](https://arxiv.org/abs/2206.06192) | Switchboard benchmark | Toward Zero Oracle Word Error Rate on the Switchboard Benchmark| [![arXiv](https://img.shields.io/badge/arXiv-2022-brightgreen)](https://arxiv.org/abs/2206.06192) | [![Benchmarks.AI](https://img.shields.io/badge/Website-Benchmarks.AI-red)](https://benchmarks.ai/switchboard) | <details><summary>Summary</summary> The study presents a detailed evaluation of the Switchboard benchmark in automatic speech recognition, highlighting key improvements. By employing a professional linguist to correct reference transcripts, the word error rate (WER) was substantially improved. The paper suggests alternatives to standard WER scoring, including transcript precision and recall, better reflecting human transcription tendencies. It examines various ASR alternative representations (utterance-level, word-level, and phrase-level) and showcases the effectiveness of phrase alternatives in achieving near-perfect oracle accuracy. The study also benchmarks commercial ASR systems against human services and underscores the potential of advanced ASR technologies in applications like audio search.  </details> |
| [2019](https://aclanthology.org/N19-1072/) | LitePyramid | Crowdsourcing Lightweight Pyramids for Manual Summary Evaluation | [![Paper](https://img.shields.io/badge/Conference-ACL'19-blue)](https://aclanthology.org/N19-1072/) | [![GitHub](https://img.shields.io/github/stars/OriShapira/LitePyramids.svg?style=social)](https://github.com/OriShapira/LitePyramids) | <details><summary>Summary</summary> The study introduces a crowdsourced, lightweight version of the Pyramid method for manual summary evaluation, addressing the traditional Pyramid's high cost and complexity. This new method employs a sampling-based approach to extract Summary Content Units (SCUs) from reference summaries and uses crowdsourcing for evaluating system summaries. Tested using the DUC 2005 and 2006 datasets, it demonstrates a higher correlation with original Pyramid scores than with the Responsiveness method, suggesting greater reliability. The study also explores the balance between resource allocation and evaluation quality, indicating potential for cost efficiency and adaptability. It paves the way for reliable, scalable summary evaluations in future research </details> |
| [2019](https://arxiv.org/abs/1804.07461) | GLUE | General Language Understanding Evaluation (GLUE) benchmark | [![arXiv](https://img.shields.io/badge/arXiv-2019-brightgreen)](https://arxiv.org/abs/1804.07461) | [![GLUE Benchmark](https://img.shields.io/badge/Website-GLUE_Benchmark-red)](https://gluebenchmark.com/) | <details><summary>Summary</summary> The General Language Understanding Evaluation (GLUE) benchmark is a collection of tools for evaluating models on a variety of natural language understanding tasks. It features tasks like sentiment analysis and question answering, aiming to advance models that generalize across diverse linguistic tasks. GLUE emphasizes the importance of models sharing knowledge across tasks, particularly when training data is limited. Evaluation of baseline models, including ELMo, shows that multi-task training is more effective than single-task training. However, there is a significant need for improvement in overall model performance, especially in areas like logical reasoning, indicating fertile ground for future NLU research. </details> |
| [2019](https://arxiv.org/abs/1908.06177) | CLUTRR (Meta) | A Diagnostic Benchmark for Inductive Reasoning from Text | [![arXiv](https://img.shields.io/badge/arXiv-2019-brightgreen)](https://arxiv.org/abs/1908.06177) | [![GitHub](https://img.shields.io/github/stars/facebookresearch/clutrr.svg?style=social)](https://github.com/facebookresearch/clutrr) | <details><summary>Summary</summary> CLUTRR is a benchmark suite designed to test NLU systems' robustness and generalization capabilities using inductive reasoning on kinship relations in short stories. It combines semi-synthetic stories based on kinship graphs and crowd-sourced narratives, assessing systematic generalization on unseen logical combinations and robustness against noise. Comparative studies reveal performance gaps between traditional NLU models like BERT and graph-based models such as GAT, especially in reasoning with unstructured text. CLUTRR's diagnostic capabilities underscore the challenges in machine reasoning and point towards the need for more advanced, robust NLU systems capable of handling diverse linguistic tasks and generalizing systematically. </details> |
| [2016](https://arxiv.org/abs/1606.05250) | SQuAD | 100,000+ Questions for Machine Comprehension of Text | [![arXiv](https://img.shields.io/badge/arXiv-2016-brightgreen)](https://arxiv.org/abs/1606.05250) | [![GitHub](https://img.shields.io/github/stars/rajpurkar/SQuAD-explorer.svg?style=social)](https://rajpurkar.github.io/SQuAD-explorer/) | <details><summary>Summary</summary> The Stanford Question Answering Dataset (SQuAD) is a large-scale dataset for advancing machine comprehension of text, comprising over 100,000 questions formulated by crowdworkers based on Wikipedia articles. Each question is designed to have answers that are segments from the text, presenting a significant challenge in natural language understanding and world knowledge. The dataset exhibits a diverse range of question types and answer formats, highlighting the complexity of the reading comprehension task. While human performance notably surpasses machine models on SQuAD, it underscores the potential for future research and development in this area, making it a valuable resource for the natural language processing and machine learning communities. </details> |
| [2012](https://arxiv.org/abs/1207.4708) | Atari | The Arcade Learning Environment: An Evaluation Platform for General Agents | [![arXiv](https://img.shields.io/badge/arXiv-2012-brightgreen)](https://arxiv.org/abs/1207.4708) | [![GitHub](https://img.shields.io/github/stars/Farama-Foundation/Arcade-Learning-Environment.svg?style=social)](https://github.com/Farama-Foundation/Arcade-Learning-Environment) | <details><summary>Summary</summary> competency of AI agents, offering an interface to a wide array of Atari 2600 games. Each game presents unique challenges, providing a comprehensive testbed for techniques in reinforcement learning, planning, and other AI domains. The ALE facilitates benchmarking against well-established AI methods, demonstrated through empirical evaluations across over 55 diverse games. All software and benchmark agents are made publicly available, supporting widespread research use. This initiative represents a significant step in AI research, pushing towards achieving general competency across a wide range of Atari 2600 games. </details> |
| [2012](https://ieeexplore.ieee.org/document/6296535) | MNIST | Database of Handwritten Digit Images for Machine Learning Research | [![Paper](https://img.shields.io/badge/Conference-IEEE-blue)](https://ieeexplore.ieee.org/document/6296535) | [![MNIST](https://img.shields.io/badge/Website-MNIST-red)](http://yann.lecun.com/exdb/mnist/) | <details><summary>Summary</summary> The MNIST database is a fundamental resource in machine learning and pattern recognition, consisting of 60,000 training and 10,000 test images of handwritten digits. Originating from the NIST database, it offers standardized, size-normalized, and centered images for algorithm benchmarking. Its widespread use allows for effective comparison of new machine learning algorithms against established ones, particularly highlighting the superiority of convolutional neural networks, especially when using data augmentation techniques like elastic distortion. MNIST serves as an accessible starting point for researchers and students, facilitating exploration of machine learning techniques with minimal preprocessing effort, analogous to the role of the TIMIT database in speech processing research. </details> |
| [2009](https://ieeexplore.ieee.org/document/5206848) | ImageNet | Image database organized according to the WordNet hierarchy (currently only the nouns) | [![Paper](https://img.shields.io/badge/Conference-IEEE-blue)](https://ieeexplore.ieee.org/document/5206848) | [![ImageNet](https://img.shields.io/badge/Website-ImageNet-red)](https://www.image-net.org/) | <details><summary>Summary</summary>ImageNet is a large-scale hierarchical image database built upon the WordNet structure, aiming to populate thousands of synsets with millions of high-quality, human-annotated images. The current state features 12 subtrees with 5247 synsets, totaling 3.2 million images. It surpasses other image datasets in scale, accuracy, and diversity. ImageNet is constructed using Amazon Mechanical Turk, ensuring precise and quality-controlled images. Its hierarchical structure and semantic organization offer unique advantages for various computer vision applications, including object recognition and image classification. Future goals include expanding the database to around 50 million images and fostering a collaborative community platform. </details> |


## Generative AI Impactful Projects

| Publication Year | Name | Description | Paper Link | GitHub Link | Summary |
| ---------------- | ---- | ----------- | ---------- | ----------- | ------- |
| [2023](https://github.com/facebookresearch/fairseq/) | Fairseq (Meta) | Toolkit for LLM's | various (see GitHub page) | [![GitHub](https://img.shields.io/github/stars/facebookresearch/fairseq.svg?style=social)](https://github.com/facebookresearch/fairseq/) | <details><summary>Summary</summary> Fairseq, by Facebook AI Research, is an extensible Python toolkit for sequence modeling, particularly for tasks like translation, summarization, language modeling, and other text generation tasks. It has a variety of implemented papers and offers multi-GPU training, fast generation on CPU/GPU, mixed precision training, and extensive configuration options. Recent updates include new models and code releases for diverse speech technology, unsupervised speech recognition, and more. It integrates with xFormers and provides pre-trained models through a torch.hub interface. For installation, it requires PyTorch (version >= 1.10.0), Python (version >= 3.8), and NVIDIA GPU for model training. Fairseq's versatility, community support, and continuous updates make it a powerful resource for researchers and developers in AI and machine learning fields. </details> |
| [2023](https://arxiv.org/abs/2203.17189) | T5X | Toolkit for LLM's | [![arXiv](https://img.shields.io/badge/arXiv-2023-brightgreen)](https://arxiv.org/abs/2203.17189) | [![GitHub](https://img.shields.io/github/stars/google-research/t5x.svg?style=social)](https://github.com/google-research/t5x) | <details><summary>Summary</summary> t5x and seqio are libraries developed to facilitate the scaling of large language models, addressing challenges in computation distribution and data management. t5x simplifies building and training Transformer models, leveraging JAX and Flax for efficient scaling. It supports data, parameter, and activation partitioning via XLA GSPMD and `jax.pjit`. seqio, on the other hand, manages data pipelines and evaluations through a task-based API, featuring deterministic pipelines for improved training robustness. These libraries have been widely adopted for both research and product applications, with ongoing development and improvements based on user feedback, demonstrating their practicality and impact in the field of large-scale machine learning. </details> |
| [2020](https://aclanthology.org/2020.acl-main.463/) | Octopus Paper | Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data | [![Conference](https://img.shields.io/badge/Conference-ACL'20-blue)](https://aclanthology.org/2020.acl-main.463/) | N/A | <details><summary>Summary</summary> This paper challenges the notion that large neural language models (LMs), like BERT, understand language meaning by merely training on linguistic form (text data). It argues that understanding necessitates relating linguistic forms to communicative intents external to language, a dimension not captured by current LMs. The paper draws parallels with human language acquisition, highlighting the role of interaction and real-world grounding, absent in machine learning approaches. Thought experiments illustrate the limitations of learning meaning from form. The authors call for more grounded, realistic approaches in natural language understanding (NLU) research, emphasizing accuracy in claims about language model capabilities and the importance of contextual and real-world learning. </details> |
| [2019](https://arxiv.org/abs/1910.10683) | T5 (Meta) | text to text transfer transformer | [![arXiv](https://img.shields.io/badge/arXiv-2019-brightgreen)](https://arxiv.org/abs/1910.10683) | [![GitHub](https://img.shields.io/github/stars/google-research/text-to-text-transfer-transformer.svg?style=social)](https://github.com/google-research/text-to-text-transfer-transformer) | <details><summary>Summary</summary> This paper introduces a unified framework for NLP transfer learning by converting various language tasks into a text-to-text format, implemented through the Text-to-Text Transfer Transformer (T5). It involves pre-training on the Colossal Clean Crawled Corpus (C4), a large English text dataset. The study systematically explores different aspects of transfer learning, including varying model architectures, pre-training objectives, characteristics of unlabeled datasets, and fine-tuning methods. A particular focus is on the impact of scaling model and data sizes. The integration of insights from these explorations with large-scale applications enables the achievement of state-of-the-art results on a range of language understanding benchmarks. </details> |


## Useful AI tools (2024) - There's literally an AI for everything

- [![Website](https://img.shields.io/badge/Website-CodeLlama-red)](https://codellama.dev/about) - Explore CodeLlama, a platform for LLM chatbots.
- [![Website](https://img.shields.io/badge/Website-OpenAI_ChatGPT-red)](https://openai.com/) - Learn about OpenAI's ChatGPT technology.
- [![Website](https://img.shields.io/badge/Website-Claude-red)](https://claude.ai/chats) - Discover Claude's AI chat capabilities.
- [![Website](https://img.shields.io/badge/Website-Bing_Chat_GPT4-red)](https://www.bing.com/search?q=Bing+AI&showconv=1) - Experience Bing Chat powered by GPT-4.
- [![Website](https://img.shields.io/badge/Website-Gemini_by_Google-red)](https://deepmind.google/technologies/gemini/#introduction) - Introduction to Gemini, Google's AI technology.

- [![Website](https://img.shields.io/badge/Website-2023_Generative_AI_Landscape_Link_1-red)](https://www.linkedin.com/pulse/generative-ai-landscape-2023-florian-belschner/) - "2023 Generative AI Landscape" on LinkedIn by Florian Belschner.

- [![Website](https://img.shields.io/badge/Website-2023_Generative_AI_Landscape_Link_2-red)](https://www.datacamp.com/cheat-sheet/the-generative-ai-tools-landscape) - "The Generative AI Tools Landscape" on DataCamp.

![generative AI landscape](https://github.com/Brandonio-c/NeuroAI-Cognition-Hub/assets/76982807/8c5de914-1b44-4c79-a416-d9b5de249acf)


<!--
(follow the link above to find a generative model listed under the subheading below) 

### Text Applications  

| Application space                                | Number of apps   |
| ------------------------------------------------ | -----------------|
| Search: Internet                                 | 8                |
| Search: Enterprise, Sales, Marketing & Accounting | 7                |
| Search: Jobs                                     | 5                |
| Search: Books, Images, Podcasts, Videos, & TV     | 9                |
| Search: Research                                  | 7                |
| Search: Programming/Software Development         | 5               |
| Chat                                              | 3              |
| Sales & Marketing Copy Generation                | 17               |
| Email Generation                                  | 8                |
| Other Copy Generation                             | 9               |
| Note-Taking & Document Summarization              | 6                |
| Writing Assistance & Translation                 | 3                |

### Image Applications

| Application space                                | Number of apps   |
| ------------------------------------------------ | -----------------|
| 2D Image Generation                              | 16              |
| Web Design, Color Palette Generation             | 6                |
| Image Editing, Enhancement & Style Transfer      | 7               |
| Ad Generation                                    | 5                |
| Presentations/Slide Generation                   | 10               |
| 3D Image Generation                              | 6                |
| Digital People Generation                        | 6                |

### Video Applications

| Application space                                | Number of apps   |
| ------------------------------------------------ | -----------------|
| Video Generation From Text                       | 6                |
| Video Editing                                    | 6               |
| Video Personalization & Derivative Content Generation | 7             |    

### Audio Applications

| Application space                                | Number of apps   |
| ------------------------------------------------ | -----------------|
| Music Generation                                 | 12               |
| Text to Speech                                   | 12               |

### Speech to Text (Transcription) 

| Application space                                | Number of apps   |
| ------------------------------------------------ | -----------------|
| Transcription: General                           | 10               |
| Transcription: Note Taking                       | 7                |
| Transcription: Subtitle Generation               | 6                |
| Transcription: Podcasts                          | 3               |
| Transcription: APIs                              | 2                 |
| Transcription: Other                             | 5                | 
| Dubbing                                          | 6               |
| Music Editing & Processing                       | 6                |
| Speech Editing & Processing                      | 5                |

### Coding Applications 

| Application space                                | Number of apps   |
| ------------------------------------------------ | -----------------|
| Website Generation from Text                     | 7                 | 
| Website Generation from Figma Designs            | 3                |
| Website Personalization & Optimization           | 4                 |
| Code Generation/Completion                       | 12                |
| Code Analysis & DevOps Intelligence              | 9                |
| Documentation Generation                         | 5                |

### Data Applications

| Application space                                | Number of apps   |
| ------------------------------------------------ | -----------------|
| Automated Analysis & Insights                    | 18              |
| Machine Learning & DataOps                       | 8                |
| Synthetic Training Data Generation               | 6                |

### Bots 

| Application space                                | Number of apps   |
| ------------------------------------------------ | -----------------|
| Chatbots                                         | 18               |
| Personal Assistants & AI Agents                  | 13               |
| Gaming                                           | 5                |
| Drug Development                                 | 4              |
| Language Learning                                |  11               |

### Miscellaneous 

| Application space                                | Number of apps   |
| ------------------------------------------------ | -----------------|
| Miscellaneous                                    | 6                |

-->


## Links to other useful GitHub pages

- [![Star](https://img.shields.io/github/stars/horseee/Awesome-Efficient-LLM.svg?style=social)](https://github.com/horseee/Awesome-Efficient-LLM) [Awesome-Efficient-LLM](https://github.com/horseee/Awesome-Efficient-LLM) - A comprehensive collection of resources on Efficient Large Language Models.
- [![Star](https://img.shields.io/github/stars/asahi417/AnalogyTools.svg?style=social)](https://github.com/asahi417/AnalogyTools) [AnalogyTools](https://github.com/asahi417/AnalogyTools) - Repository dedicated to tools for analogy-based learning and reasoning in AI.
- [![Star](https://img.shields.io/github/stars/totogo/awesome-knowledge-graph.svg?style=social)](https://github.com/totogo/awesome-knowledge-graph) [Awesome-Knowledge-Graph](https://github.com/totogo/awesome-knowledge-graph) - A curated list of awesome knowledge graph resources, papers, and tools.


## Usage

This repository primarily serves as a collection of links and references. You can explore the content by browsing the directories or using the search functionality on GitHub. Feel free to use the information here for your research, projects, or personal learning.

## Contributing

If you have valuable resources, papers, or articles related to neuro-symbolic AI and cognition within AI, we encourage you to contribute to this repository. Please follow the guidelines in our [Contribution Guidelines](CONTRIBUTING.md).

## License

This repository is open-source and is available under the [GNU Licence](LICENSE). Feel free to use and share the content while respecting the terms of the license.

We hope this repository helps you on your journey to understanding and exploring the exciting world of neuro-symbolic AI and cognition within AI. If you have any questions or suggestions, don't hesitate to [reach out](#contact-information).

Thank you for visiting!

---

### Contact Information

For inquiries or suggestions, please contact [Brandon Colelough](mailto:brandcol@umd.edu).
